{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # idx = 0\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+1:idx+self.numFeat+self.numOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 1\n",
    "train_data = dataSetAll(1998,2001,numFeat,numOut)\n",
    "test_data = dataSetAll(2001,2003,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64,drop_last=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64,drop_last=False)\n",
    "# print(next(iter(train_dataloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 1\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 64\n",
    "batchSize = 64\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numLayers,sequenceLength=1,future=0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.future = future\n",
    "        self.lstm1 = nn.LSTMCell(1,hiddenSize,bias=False)\n",
    "        self.lstm2 = nn.LSTMCell(hiddenSize,hiddenSize,bias=False)\n",
    "        self.fc = nn.Linear(hiddenSize,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # out, _ = self.LSTM(x) #lstm with input, hidden, and internal state\n",
    "        # out = self.fc(out[:,-1,:])\n",
    "        # return out\n",
    "        outputs = []\n",
    "        nSamples = x.size(0)\n",
    "        h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        c_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        h_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        c_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        \n",
    "        for input in x.split(1,dim=1):\n",
    "            h_1, _ = self.lstm1(input, (h_1,c_1))\n",
    "            # h_2, _ = self.lstm2(h_1, (h_2,c_2))\n",
    "            out = self.fc(h_1)\n",
    "            outputs.append(out)\n",
    "\n",
    "        for i in range(self.future):\n",
    "            h_1, _ = self.lstm1(input, (h_1,c_1))\n",
    "            h_2, _ = self.lstm2(h_1, (h_2,c_2))\n",
    "            out = self.fc(h_2)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "model = LSTM(inputSize,hiddenSize,numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        # print(pred.size())\n",
    "        # print(y.size())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 7991075.000000  [    0/  145]\n",
      "loss(1): 7990531.000000  [    0/  145]\n",
      "loss(2): 7990003.000000  [    0/  145]\n",
      "loss(3): 7989478.500000  [    0/  145]\n",
      "loss(4): 7988953.000000  [    0/  145]\n",
      "loss(5): 7988392.000000  [    0/  145]\n",
      "loss(6): 7987857.000000  [    0/  145]\n",
      "loss(7): 7987324.000000  [    0/  145]\n",
      "loss(8): 7986790.500000  [    0/  145]\n",
      "loss(9): 7986255.000000  [    0/  145]\n",
      "loss(10): 7985721.500000  [    0/  145]\n",
      "loss(11): 7985186.500000  [    0/  145]\n",
      "loss(12): 7984650.500000  [    0/  145]\n",
      "loss(13): 7984115.000000  [    0/  145]\n",
      "loss(14): 7983579.000000  [    0/  145]\n",
      "loss(15): 7983045.000000  [    0/  145]\n",
      "loss(16): 7982509.000000  [    0/  145]\n",
      "loss(17): 7981974.500000  [    0/  145]\n",
      "loss(18): 7981438.500000  [    0/  145]\n",
      "loss(19): 7980902.500000  [    0/  145]\n",
      "loss(20): 7980367.000000  [    0/  145]\n",
      "loss(21): 7979832.000000  [    0/  145]\n",
      "loss(22): 7979296.000000  [    0/  145]\n",
      "loss(23): 7978761.000000  [    0/  145]\n",
      "loss(24): 7978225.500000  [    0/  145]\n",
      "loss(25): 7977689.500000  [    0/  145]\n",
      "loss(26): 7977154.500000  [    0/  145]\n",
      "loss(27): 7976619.000000  [    0/  145]\n",
      "loss(28): 7976082.500000  [    0/  145]\n",
      "loss(29): 7975548.000000  [    0/  145]\n",
      "loss(30): 7975013.000000  [    0/  145]\n",
      "loss(31): 7974477.000000  [    0/  145]\n",
      "loss(32): 7973942.500000  [    0/  145]\n",
      "loss(33): 7973406.500000  [    0/  145]\n",
      "loss(34): 7972872.000000  [    0/  145]\n",
      "loss(35): 7972336.000000  [    0/  145]\n",
      "loss(36): 7971801.500000  [    0/  145]\n",
      "loss(37): 7971266.500000  [    0/  145]\n",
      "loss(38): 7970731.000000  [    0/  145]\n",
      "loss(39): 7970196.000000  [    0/  145]\n",
      "loss(40): 7969661.000000  [    0/  145]\n",
      "loss(41): 7969126.500000  [    0/  145]\n",
      "loss(42): 7968591.000000  [    0/  145]\n",
      "loss(43): 7968056.000000  [    0/  145]\n",
      "loss(44): 7967521.500000  [    0/  145]\n",
      "loss(45): 7966985.500000  [    0/  145]\n",
      "loss(46): 7966451.000000  [    0/  145]\n",
      "loss(47): 7965917.000000  [    0/  145]\n",
      "loss(48): 7965381.500000  [    0/  145]\n",
      "loss(49): 7964847.000000  [    0/  145]\n",
      "loss(50): 7964313.500000  [    0/  145]\n",
      "loss(51): 7963777.500000  [    0/  145]\n",
      "loss(52): 7963243.000000  [    0/  145]\n",
      "loss(53): 7962709.000000  [    0/  145]\n",
      "loss(54): 7962174.500000  [    0/  145]\n",
      "loss(55): 7961640.000000  [    0/  145]\n",
      "loss(56): 7961104.000000  [    0/  145]\n",
      "loss(57): 7960570.500000  [    0/  145]\n",
      "loss(58): 7960036.000000  [    0/  145]\n",
      "loss(59): 7959501.500000  [    0/  145]\n",
      "loss(60): 7958966.500000  [    0/  145]\n",
      "loss(61): 7958433.000000  [    0/  145]\n",
      "loss(62): 7957898.500000  [    0/  145]\n",
      "loss(63): 7957364.000000  [    0/  145]\n",
      "loss(64): 7956830.500000  [    0/  145]\n",
      "loss(65): 7956296.000000  [    0/  145]\n",
      "loss(66): 7955761.500000  [    0/  145]\n",
      "loss(67): 7955227.000000  [    0/  145]\n",
      "loss(68): 7954694.500000  [    0/  145]\n",
      "loss(69): 7954160.000000  [    0/  145]\n",
      "loss(70): 7953625.500000  [    0/  145]\n",
      "loss(71): 7953093.000000  [    0/  145]\n",
      "loss(72): 7952558.500000  [    0/  145]\n",
      "loss(73): 7952023.000000  [    0/  145]\n",
      "loss(74): 7951489.500000  [    0/  145]\n",
      "loss(75): 7950957.000000  [    0/  145]\n",
      "loss(76): 7950422.500000  [    0/  145]\n",
      "loss(77): 7949888.000000  [    0/  145]\n",
      "loss(78): 7949355.000000  [    0/  145]\n",
      "loss(79): 7948821.500000  [    0/  145]\n",
      "loss(80): 7948287.000000  [    0/  145]\n",
      "loss(81): 7947753.500000  [    0/  145]\n",
      "loss(82): 7947220.000000  [    0/  145]\n",
      "loss(83): 7946687.000000  [    0/  145]\n",
      "loss(84): 7946153.500000  [    0/  145]\n",
      "loss(85): 7945620.000000  [    0/  145]\n",
      "loss(86): 7945086.500000  [    0/  145]\n",
      "loss(87): 7944553.500000  [    0/  145]\n",
      "loss(88): 7944020.000000  [    0/  145]\n",
      "loss(89): 7943486.500000  [    0/  145]\n",
      "loss(90): 7942953.000000  [    0/  145]\n",
      "loss(91): 7942419.000000  [    0/  145]\n",
      "loss(92): 7941886.500000  [    0/  145]\n",
      "loss(93): 7941353.000000  [    0/  145]\n",
      "loss(94): 7940820.000000  [    0/  145]\n",
      "loss(95): 7940286.500000  [    0/  145]\n",
      "loss(96): 7939754.500000  [    0/  145]\n",
      "loss(97): 7939221.000000  [    0/  145]\n",
      "loss(98): 7938687.000000  [    0/  145]\n",
      "loss(99): 7938154.500000  [    0/  145]\n",
      "loss(100): 7937621.500000  [    0/  145]\n",
      "loss(101): 7937089.500000  [    0/  145]\n",
      "loss(102): 7936556.000000  [    0/  145]\n",
      "loss(103): 7936023.000000  [    0/  145]\n",
      "loss(104): 7935490.500000  [    0/  145]\n",
      "loss(105): 7934957.000000  [    0/  145]\n",
      "loss(106): 7934425.000000  [    0/  145]\n",
      "loss(107): 7933892.000000  [    0/  145]\n",
      "loss(108): 7933359.000000  [    0/  145]\n",
      "loss(109): 7932827.000000  [    0/  145]\n",
      "loss(110): 7932293.500000  [    0/  145]\n",
      "loss(111): 7931761.500000  [    0/  145]\n",
      "loss(112): 7931229.000000  [    0/  145]\n",
      "loss(113): 7930697.500000  [    0/  145]\n",
      "loss(114): 7930165.000000  [    0/  145]\n",
      "loss(115): 7929633.000000  [    0/  145]\n",
      "loss(116): 7929101.000000  [    0/  145]\n",
      "loss(117): 7928568.000000  [    0/  145]\n",
      "loss(118): 7928035.000000  [    0/  145]\n",
      "loss(119): 7927503.000000  [    0/  145]\n",
      "loss(120): 7926970.500000  [    0/  145]\n",
      "loss(121): 7926438.500000  [    0/  145]\n",
      "loss(122): 7925906.500000  [    0/  145]\n",
      "loss(123): 7925375.000000  [    0/  145]\n",
      "loss(124): 7924843.000000  [    0/  145]\n",
      "loss(125): 7924310.500000  [    0/  145]\n",
      "loss(126): 7923778.500000  [    0/  145]\n",
      "loss(127): 7923246.500000  [    0/  145]\n",
      "loss(128): 7922715.000000  [    0/  145]\n",
      "loss(129): 7922183.000000  [    0/  145]\n",
      "loss(130): 7921651.000000  [    0/  145]\n",
      "loss(131): 7921119.000000  [    0/  145]\n",
      "loss(132): 7920587.000000  [    0/  145]\n",
      "loss(133): 7920055.000000  [    0/  145]\n",
      "loss(134): 7919523.000000  [    0/  145]\n",
      "loss(135): 7918992.000000  [    0/  145]\n",
      "loss(136): 7918461.500000  [    0/  145]\n",
      "loss(137): 7917929.500000  [    0/  145]\n",
      "loss(138): 7917398.500000  [    0/  145]\n",
      "loss(139): 7916866.500000  [    0/  145]\n",
      "loss(140): 7916335.000000  [    0/  145]\n",
      "loss(141): 7915802.500000  [    0/  145]\n",
      "loss(142): 7915272.000000  [    0/  145]\n",
      "loss(143): 7914742.500000  [    0/  145]\n",
      "loss(144): 7914210.500000  [    0/  145]\n",
      "loss(145): 7913679.000000  [    0/  145]\n",
      "loss(146): 7913149.000000  [    0/  145]\n",
      "loss(147): 7912619.000000  [    0/  145]\n",
      "loss(148): 7912088.000000  [    0/  145]\n",
      "loss(149): 7911557.500000  [    0/  145]\n",
      "loss(150): 7911029.000000  [    0/  145]\n",
      "loss(151): 7910498.500000  [    0/  145]\n",
      "loss(152): 7909968.000000  [    0/  145]\n",
      "loss(153): 7909438.500000  [    0/  145]\n",
      "loss(154): 7908907.000000  [    0/  145]\n",
      "loss(155): 7908378.500000  [    0/  145]\n",
      "loss(156): 7907849.000000  [    0/  145]\n",
      "loss(157): 7907318.500000  [    0/  145]\n",
      "loss(158): 7906788.000000  [    0/  145]\n",
      "loss(159): 7906260.000000  [    0/  145]\n",
      "loss(160): 7905729.500000  [    0/  145]\n",
      "loss(161): 7905200.000000  [    0/  145]\n",
      "loss(162): 7904670.500000  [    0/  145]\n",
      "loss(163): 7904140.000000  [    0/  145]\n",
      "loss(164): 7903610.500000  [    0/  145]\n",
      "loss(165): 7903081.500000  [    0/  145]\n",
      "loss(166): 7902552.000000  [    0/  145]\n",
      "loss(167): 7902022.500000  [    0/  145]\n",
      "loss(168): 7901493.000000  [    0/  145]\n",
      "loss(169): 7900964.000000  [    0/  145]\n",
      "loss(170): 7900435.000000  [    0/  145]\n",
      "loss(171): 7899904.000000  [    0/  145]\n",
      "loss(172): 7899376.000000  [    0/  145]\n",
      "loss(173): 7898846.500000  [    0/  145]\n",
      "loss(174): 7898317.000000  [    0/  145]\n",
      "loss(175): 7897789.000000  [    0/  145]\n",
      "loss(176): 7897259.000000  [    0/  145]\n",
      "loss(177): 7896730.500000  [    0/  145]\n",
      "loss(178): 7896200.000000  [    0/  145]\n",
      "loss(179): 7895672.000000  [    0/  145]\n",
      "loss(180): 7895142.500000  [    0/  145]\n",
      "loss(181): 7894613.000000  [    0/  145]\n",
      "loss(182): 7894085.000000  [    0/  145]\n",
      "loss(183): 7893555.000000  [    0/  145]\n",
      "loss(184): 7893025.500000  [    0/  145]\n",
      "loss(185): 7892497.000000  [    0/  145]\n",
      "loss(186): 7891968.000000  [    0/  145]\n",
      "loss(187): 7891438.500000  [    0/  145]\n",
      "loss(188): 7890909.000000  [    0/  145]\n",
      "loss(189): 7890381.000000  [    0/  145]\n",
      "loss(190): 7889852.000000  [    0/  145]\n",
      "loss(191): 7889322.500000  [    0/  145]\n",
      "loss(192): 7888793.500000  [    0/  145]\n",
      "loss(193): 7888265.500000  [    0/  145]\n",
      "loss(194): 7887735.000000  [    0/  145]\n",
      "loss(195): 7887205.500000  [    0/  145]\n",
      "loss(196): 7886677.000000  [    0/  145]\n",
      "loss(197): 7886147.000000  [    0/  145]\n",
      "loss(198): 7885616.000000  [    0/  145]\n",
      "loss(199): 7885085.500000  [    0/  145]\n",
      "loss(200): 7884555.000000  [    0/  145]\n",
      "loss(201): 7884024.000000  [    0/  145]\n",
      "loss(202): 7883493.000000  [    0/  145]\n",
      "loss(203): 7882961.500000  [    0/  145]\n",
      "loss(204): 7882433.000000  [    0/  145]\n",
      "loss(205): 7881904.000000  [    0/  145]\n",
      "loss(206): 7881374.500000  [    0/  145]\n",
      "loss(207): 7880845.000000  [    0/  145]\n",
      "loss(208): 7880315.000000  [    0/  145]\n",
      "loss(209): 7879785.500000  [    0/  145]\n",
      "loss(210): 7879253.000000  [    0/  145]\n",
      "loss(211): 7878721.000000  [    0/  145]\n",
      "loss(212): 7878192.000000  [    0/  145]\n",
      "loss(213): 7877664.000000  [    0/  145]\n",
      "loss(214): 7877136.000000  [    0/  145]\n",
      "loss(215): 7876608.000000  [    0/  145]\n",
      "loss(216): 7876080.000000  [    0/  145]\n",
      "loss(217): 7875550.500000  [    0/  145]\n",
      "loss(218): 7875023.000000  [    0/  145]\n",
      "loss(219): 7874495.000000  [    0/  145]\n",
      "loss(220): 7873966.500000  [    0/  145]\n",
      "loss(221): 7873439.000000  [    0/  145]\n",
      "loss(222): 7872909.500000  [    0/  145]\n",
      "loss(223): 7872381.500000  [    0/  145]\n",
      "loss(224): 7871854.500000  [    0/  145]\n",
      "loss(225): 7871325.500000  [    0/  145]\n",
      "loss(226): 7870797.500000  [    0/  145]\n",
      "loss(227): 7870270.500000  [    0/  145]\n",
      "loss(228): 7869741.500000  [    0/  145]\n",
      "loss(229): 7869214.500000  [    0/  145]\n",
      "loss(230): 7868686.500000  [    0/  145]\n",
      "loss(231): 7868158.500000  [    0/  145]\n",
      "loss(232): 7867631.000000  [    0/  145]\n",
      "loss(233): 7867104.000000  [    0/  145]\n",
      "loss(234): 7866576.000000  [    0/  145]\n",
      "loss(235): 7866048.000000  [    0/  145]\n",
      "loss(236): 7865521.000000  [    0/  145]\n",
      "loss(237): 7864993.000000  [    0/  145]\n",
      "loss(238): 7864465.500000  [    0/  145]\n",
      "loss(239): 7863937.500000  [    0/  145]\n",
      "loss(240): 7863411.000000  [    0/  145]\n",
      "loss(241): 7862884.000000  [    0/  145]\n",
      "loss(242): 7862357.000000  [    0/  145]\n",
      "loss(243): 7861829.000000  [    0/  145]\n",
      "loss(244): 7861301.500000  [    0/  145]\n",
      "loss(245): 7860774.500000  [    0/  145]\n",
      "loss(246): 7860247.000000  [    0/  145]\n",
      "loss(247): 7859719.000000  [    0/  145]\n",
      "loss(248): 7859193.000000  [    0/  145]\n",
      "loss(249): 7858665.500000  [    0/  145]\n",
      "loss(250): 7858138.500000  [    0/  145]\n",
      "loss(251): 7857612.000000  [    0/  145]\n",
      "loss(252): 7857085.000000  [    0/  145]\n",
      "loss(253): 7856558.500000  [    0/  145]\n",
      "loss(254): 7856031.000000  [    0/  145]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .01\n",
    "batch_size = 64\n",
    "epochs = 5000\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "def graph(model):\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:]\n",
    "            pred = model(X)\n",
    "            predY.append(pred.numpy()[0][-1])\n",
    "            actY.append(y.numpy()[-1])\n",
    "            # plt.plot(np.append(feat,pred))\n",
    "            # plt.plot(np.append(feat,y))\n",
    "            \n",
    "            \n",
    "        \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "graph(model)\n",
    "# test_loop(test_dataloader,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
