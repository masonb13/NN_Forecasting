{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # idx = 0\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 1\n",
    "train_data = dataSetAll(1900,2013,numFeat,numOut)\n",
    "test_data = dataSetAll(2013,2100,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=100,drop_last=False,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100,drop_last=False,shuffle=True)\n",
    "# print(next(iter(train_dataloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create our RNN based network with an RNN followed by a linear layer\n",
    "# inputSize = 1\n",
    "# sequenceLength = numFeat\n",
    "# numLayers = 1\n",
    "# hiddenSize = 32\n",
    "# batchSize = 100\n",
    "\n",
    "# class LSTM(nn.Module):\n",
    "#     def __init__(self,inputSize,hiddenSize,numLayers):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.inputSize = inputSize\n",
    "#         self.hiddenSize = hiddenSize\n",
    "#         self.numLayers = numLayers\n",
    "#         # print(batchSize,sequenceLength,inputSize)\n",
    "#         self.LSTM = nn.LSTM(inputSize,hiddenSize,numLayers,batch_first=True)\n",
    "#         # self.lstm1 = nn.LSTMCell(1,hiddenSize,bias=False)\n",
    "#         # self.lstm2 = nn.LSTMCell(hiddenSize,hiddenSize,bias=False)\n",
    "#         self.fc = nn.Linear(hiddenSize,1)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         # print(x.size())\n",
    "#         out, _ = self.LSTM(x) #lstm with input, hidden, and internal state\n",
    "#         out = self.fc(out[:,-1,:])\n",
    "#         return out\n",
    "#         # outputs = []\n",
    "#         # nSamples = x.size(0)\n",
    "#         # h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "#         # c_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "#         # h_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "#         # c_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        \n",
    "#         # for input in x.split(1,dim=1):\n",
    "#         #     h_1, _ = self.lstm1(input, (h_1,c_1))\n",
    "#         #     # h_2, _ = self.lstm2(h_1, (h_2,c_2))\n",
    "#         #     out = self.fc(h_1)\n",
    "#         #     outputs.append(out)\n",
    "\n",
    "#         # for i in range(self.future):\n",
    "#         #     h_1, _ = self.lstm1(input, (h_1,c_1))\n",
    "#         #     # h_2, _ = self.lstm2(h_1, (h_2,c_2))\n",
    "#         #     out = self.fc(h_1)\n",
    "#         #     outputs.append(out)\n",
    "        \n",
    "#         # outputs = torch.cat(outputs, dim=1)\n",
    "#         # return outputs\n",
    "\n",
    "# model = LSTM(inputSize,hiddenSize,numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(X.size())\n",
    "        X = X[:,:,None]\n",
    "        pred = model(X)\n",
    "        # print(pred.size())\n",
    "        # print(y.size())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 43923292.000000  [    0/  782]\n",
      "loss(1): 54222640.000000  [    0/  782]\n",
      "loss(2): 34840144.000000  [    0/  782]\n",
      "loss(3): 58759036.000000  [    0/  782]\n",
      "loss(4): 35890464.000000  [    0/  782]\n",
      "loss(5): 37953264.000000  [    0/  782]\n",
      "loss(6): 53351876.000000  [    0/  782]\n",
      "loss(7): 35724616.000000  [    0/  782]\n",
      "loss(8): 37718440.000000  [    0/  782]\n",
      "loss(9): 40170900.000000  [    0/  782]\n",
      "loss(10): 25049500.000000  [    0/  782]\n",
      "loss(11): 46014812.000000  [    0/  782]\n",
      "loss(12): 45944340.000000  [    0/  782]\n",
      "loss(13): 53326332.000000  [    0/  782]\n",
      "loss(14): 26013428.000000  [    0/  782]\n",
      "loss(15): 49552384.000000  [    0/  782]\n",
      "loss(16): 27534010.000000  [    0/  782]\n",
      "loss(17): 34214720.000000  [    0/  782]\n",
      "loss(18): 20405960.000000  [    0/  782]\n",
      "loss(19): 34893088.000000  [    0/  782]\n",
      "loss(20): 35590272.000000  [    0/  782]\n",
      "loss(21): 40567056.000000  [    0/  782]\n",
      "loss(22): 20840392.000000  [    0/  782]\n",
      "loss(23): 20904788.000000  [    0/  782]\n",
      "loss(24): 25229384.000000  [    0/  782]\n",
      "loss(25): 33744436.000000  [    0/  782]\n",
      "loss(26): 57477944.000000  [    0/  782]\n",
      "loss(27): 41677208.000000  [    0/  782]\n",
      "loss(28): 31612516.000000  [    0/  782]\n",
      "loss(29): 36295740.000000  [    0/  782]\n",
      "loss(30): 35569072.000000  [    0/  782]\n",
      "loss(31): 38393356.000000  [    0/  782]\n",
      "loss(32): 22665414.000000  [    0/  782]\n",
      "loss(33): 24894912.000000  [    0/  782]\n",
      "loss(34): 37801044.000000  [    0/  782]\n",
      "loss(35): 31868252.000000  [    0/  782]\n",
      "loss(36): 35195520.000000  [    0/  782]\n",
      "loss(37): 37125324.000000  [    0/  782]\n",
      "loss(38): 24594934.000000  [    0/  782]\n",
      "loss(39): 34504096.000000  [    0/  782]\n",
      "loss(40): 29413364.000000  [    0/  782]\n",
      "loss(41): 31756930.000000  [    0/  782]\n",
      "loss(42): 53424820.000000  [    0/  782]\n",
      "loss(43): 20771706.000000  [    0/  782]\n",
      "loss(44): 51202852.000000  [    0/  782]\n",
      "loss(45): 33074512.000000  [    0/  782]\n",
      "loss(46): 39468804.000000  [    0/  782]\n",
      "loss(47): 35272748.000000  [    0/  782]\n",
      "loss(48): 29826852.000000  [    0/  782]\n",
      "loss(49): 45098188.000000  [    0/  782]\n",
      "loss(50): 25943088.000000  [    0/  782]\n",
      "loss(51): 28208386.000000  [    0/  782]\n",
      "loss(52): 36128984.000000  [    0/  782]\n",
      "loss(53): 56395224.000000  [    0/  782]\n",
      "loss(54): 30163080.000000  [    0/  782]\n",
      "loss(55): 41360668.000000  [    0/  782]\n",
      "loss(56): 30907238.000000  [    0/  782]\n",
      "loss(57): 26417132.000000  [    0/  782]\n",
      "loss(58): 29768376.000000  [    0/  782]\n",
      "loss(59): 34687800.000000  [    0/  782]\n",
      "loss(60): 33976624.000000  [    0/  782]\n",
      "loss(61): 32031578.000000  [    0/  782]\n",
      "loss(62): 50864208.000000  [    0/  782]\n",
      "loss(63): 46763624.000000  [    0/  782]\n",
      "loss(64): 27153410.000000  [    0/  782]\n",
      "loss(65): 31299778.000000  [    0/  782]\n",
      "loss(66): 29370448.000000  [    0/  782]\n",
      "loss(67): 22378192.000000  [    0/  782]\n",
      "loss(68): 23601264.000000  [    0/  782]\n",
      "loss(69): 43772860.000000  [    0/  782]\n",
      "loss(70): 30313044.000000  [    0/  782]\n",
      "loss(71): 25154348.000000  [    0/  782]\n",
      "loss(72): 56969304.000000  [    0/  782]\n",
      "loss(73): 24254604.000000  [    0/  782]\n",
      "loss(74): 26466928.000000  [    0/  782]\n",
      "loss(75): 35861664.000000  [    0/  782]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# print(X.size())\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X \u001b[39m=\u001b[39m X[:,:,\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(pred.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# print(y.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# print(x.size())\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLSTM(x) \u001b[39m#lstm with input, hidden, and internal state\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    775\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    776\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = .01\n",
    "batch_size = 100\n",
    "epochs = 500\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# print(list(model.parameters()))\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "def graph(model):\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            # print(X.size())\n",
    "            pred = model(X)\n",
    "            predY.append(pred.numpy()[0][-1])\n",
    "            actY.append(y.numpy()[-1])\n",
    "            # plt.plot(np.append(feat,pred))\n",
    "            # plt.plot(np.append(feat,y))\n",
    "            \n",
    "            \n",
    "        \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "graph(model)\n",
    "# test_loop(test_dataloader,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
