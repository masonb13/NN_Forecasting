{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 1\n",
    "train_data = dataSetAll(1900,2013,numFeat,numOut)\n",
    "test_data = dataSetAll(2013,2100,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64,drop_last=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 1\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 64\n",
    "batchSize = 64\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numLayers,sequenceLength=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.LSTM = nn.LSTM(inputSize,hiddenSize,numLayers,batch_first=True)\n",
    "        self.fc = nn.Linear(hiddenSize*sequenceLength,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out, _ = self.LSTM(x) #lstm with input, hidden, and internal state\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "        \n",
    "\n",
    "model = LSTM(inputSize,hiddenSize,numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 5752549.000000  [    0/  782]\n",
      "loss(1): 5736817.000000  [    0/  782]\n",
      "loss(2): 6309034.000000  [    0/  782]\n",
      "loss(3): 7297274.000000  [    0/  782]\n",
      "loss(4): 7075670.000000  [    0/  782]\n",
      "loss(5): 7054039.000000  [    0/  782]\n",
      "loss(6): 6746197.500000  [    0/  782]\n",
      "loss(7): 6737590.500000  [    0/  782]\n",
      "loss(8): 6733406.500000  [    0/  782]\n",
      "loss(9): 6679936.000000  [    0/  782]\n",
      "loss(10): 7147801.500000  [    0/  782]\n",
      "loss(11): 6641492.000000  [    0/  782]\n",
      "loss(12): 6620650.500000  [    0/  782]\n",
      "loss(13): 7336493.000000  [    0/  782]\n",
      "loss(14): 6431956.000000  [    0/  782]\n",
      "loss(15): 6712514.500000  [    0/  782]\n",
      "loss(16): 8372889.000000  [    0/  782]\n",
      "loss(17): 7628109.000000  [    0/  782]\n",
      "loss(18): 7491476.500000  [    0/  782]\n",
      "loss(19): 7466187.500000  [    0/  782]\n",
      "loss(20): 7444334.500000  [    0/  782]\n",
      "loss(21): 7414466.000000  [    0/  782]\n",
      "loss(22): 7393896.000000  [    0/  782]\n",
      "loss(23): 7372441.000000  [    0/  782]\n",
      "loss(24): 7353218.000000  [    0/  782]\n",
      "loss(25): 7325028.000000  [    0/  782]\n",
      "loss(26): 7299928.500000  [    0/  782]\n",
      "loss(27): 7278097.000000  [    0/  782]\n",
      "loss(28): 7255259.000000  [    0/  782]\n",
      "loss(29): 7234781.000000  [    0/  782]\n",
      "loss(30): 7214446.000000  [    0/  782]\n",
      "loss(31): 7194250.500000  [    0/  782]\n",
      "loss(32): 7174174.500000  [    0/  782]\n",
      "loss(33): 7154213.000000  [    0/  782]\n",
      "loss(34): 7134361.500000  [    0/  782]\n",
      "loss(35): 7114835.000000  [    0/  782]\n",
      "loss(36): 7094992.000000  [    0/  782]\n",
      "loss(37): 7075449.000000  [    0/  782]\n",
      "loss(38): 7056009.500000  [    0/  782]\n",
      "loss(39): 7036652.000000  [    0/  782]\n",
      "loss(40): 7017379.000000  [    0/  782]\n",
      "loss(41): 6998200.000000  [    0/  782]\n",
      "loss(42): 7119255.000000  [    0/  782]\n",
      "loss(43): 7092973.000000  [    0/  782]\n",
      "loss(44): 7067353.500000  [    0/  782]\n",
      "loss(45): 6431059.500000  [    0/  782]\n",
      "loss(46): 6081109.000000  [    0/  782]\n",
      "loss(47): 6307098.000000  [    0/  782]\n",
      "loss(48): 6258917.000000  [    0/  782]\n",
      "loss(49): 6216460.500000  [    0/  782]\n",
      "loss(50): 6268996.000000  [    0/  782]\n",
      "loss(51): 6349993.000000  [    0/  782]\n",
      "loss(52): 6305962.000000  [    0/  782]\n",
      "loss(53): 6264270.000000  [    0/  782]\n",
      "loss(54): 6224486.000000  [    0/  782]\n",
      "loss(55): 6187170.500000  [    0/  782]\n",
      "loss(56): 6148794.500000  [    0/  782]\n",
      "loss(57): 6112625.000000  [    0/  782]\n",
      "loss(58): 6334968.000000  [    0/  782]\n",
      "loss(59): 6301664.000000  [    0/  782]\n",
      "loss(60): 6268955.500000  [    0/  782]\n",
      "loss(61): 6236979.500000  [    0/  782]\n",
      "loss(62): 6205833.000000  [    0/  782]\n",
      "loss(63): 6175274.000000  [    0/  782]\n",
      "loss(64): 6145206.500000  [    0/  782]\n",
      "loss(65): 6115595.500000  [    0/  782]\n",
      "loss(66): 6086358.500000  [    0/  782]\n",
      "loss(67): 6057677.000000  [    0/  782]\n",
      "loss(68): 6029120.500000  [    0/  782]\n",
      "loss(69): 6002296.500000  [    0/  782]\n",
      "loss(70): 5973223.500000  [    0/  782]\n",
      "loss(71): 5964597.500000  [    0/  782]\n",
      "loss(72): 5937208.000000  [    0/  782]\n",
      "loss(73): 5638459.500000  [    0/  782]\n",
      "loss(74): 5704353.000000  [    0/  782]\n",
      "loss(75): 5679120.500000  [    0/  782]\n",
      "loss(76): 5656190.500000  [    0/  782]\n",
      "loss(77): 5637642.500000  [    0/  782]\n",
      "loss(78): 5614418.500000  [    0/  782]\n",
      "loss(79): 5592734.000000  [    0/  782]\n",
      "loss(80): 5576013.000000  [    0/  782]\n",
      "loss(81): 5547368.500000  [    0/  782]\n",
      "loss(82): 5526130.500000  [    0/  782]\n",
      "loss(83): 5504674.500000  [    0/  782]\n",
      "loss(84): 5483731.000000  [    0/  782]\n",
      "loss(85): 5463057.500000  [    0/  782]\n",
      "loss(86): 5440015.500000  [    0/  782]\n",
      "loss(87): 5419327.000000  [    0/  782]\n",
      "loss(88): 5398834.000000  [    0/  782]\n",
      "loss(89): 5378611.500000  [    0/  782]\n",
      "loss(90): 5357970.000000  [    0/  782]\n",
      "loss(91): 5337704.000000  [    0/  782]\n",
      "loss(92): 5317613.000000  [    0/  782]\n",
      "loss(93): 5503820.000000  [    0/  782]\n",
      "loss(94): 5486896.000000  [    0/  782]\n",
      "loss(95): 5465203.500000  [    0/  782]\n",
      "loss(96): 5445093.000000  [    0/  782]\n",
      "loss(97): 5427509.000000  [    0/  782]\n",
      "loss(98): 5408517.500000  [    0/  782]\n",
      "loss(99): 5388804.000000  [    0/  782]\n",
      "loss(100): 5369167.000000  [    0/  782]\n",
      "loss(101): 5350153.500000  [    0/  782]\n",
      "loss(102): 5331351.000000  [    0/  782]\n",
      "loss(103): 5311991.000000  [    0/  782]\n",
      "loss(104): 5293704.500000  [    0/  782]\n",
      "loss(105): 5275278.500000  [    0/  782]\n",
      "loss(106): 5256563.000000  [    0/  782]\n",
      "loss(107): 5238279.000000  [    0/  782]\n",
      "loss(108): 5220141.500000  [    0/  782]\n",
      "loss(109): 5201881.500000  [    0/  782]\n",
      "loss(110): 5183875.500000  [    0/  782]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X \u001b[39m=\u001b[39m X[:,:,\u001b[39mNone\u001b[39;00m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(X.size())\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(\"pred\",pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# print(\"Y\",y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLSTM(x) \u001b[39m#lstm with input, hidden, and internal state\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(out[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/LSTM.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = .05\n",
    "batch_size = 64\n",
    "epochs = 5000\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "def graph(model):\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = float(model(X).squeeze().numpy())\n",
    "            predY.append(pred)\n",
    "            actY.append(float(y))\n",
    "            # plt.plot(np.append(feat,pred))\n",
    "            # plt.plot(np.append(feat,y))\n",
    "            \n",
    "            \n",
    "        \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "graph(model)\n",
    "# test_loop(test_dataloader,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
