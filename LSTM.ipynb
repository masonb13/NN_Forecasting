{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = 10 #------------------------\n",
    "        self.numOut = 1\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat+self.numOut-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "train_data = dataSetAll(1900,2013)\n",
    "test_data = dataSetAll(2013,2100)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 1\n",
    "sequenceLength = 5\n",
    "numLayers = 1\n",
    "hiddenSize = 256\n",
    "batchSize = 64\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numLayers,sequenceLength=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.RNN = nn.RNN(inputSize,hiddenSize,numLayers,nonlinearity='relu',batch_first=True)\n",
    "        self.fc = nn.Linear(hiddenSize*sequenceLength,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.numLayers,x.size(0),self.hiddenSize)\n",
    "        out, _ = self.RNN(x,h0)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "\n",
    "model = LSTM(inputSize,hiddenSize,numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X).squeeze()\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .0001\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "test_loop(test_dataloader,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
