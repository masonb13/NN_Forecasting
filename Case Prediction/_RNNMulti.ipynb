{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CSV\n",
    "        self.df = pd.read_csv(\"data\\\\case\\\\ILINet.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][[\"ILITOTAL\",\"% WEIGHTED ILI\",\"TOTAL PATIENTS\"]]\n",
    "\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        \n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        # print(self.data)\n",
    "        self.norm = np.linalg.norm(self.data, axis=0)\n",
    "        # print(self.norm)\n",
    "        self.data = self.data / self.norm\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # idx = 0\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]\n",
    "    \n",
    "    def getNorm(self):\n",
    "        return self.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\case\\\\ILINet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m numOut \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m      4\u001b[0m batchSize \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m----> 5\u001b[0m train_data \u001b[39m=\u001b[39m dataSetAll(\u001b[39m2020\u001b[39;49m,\u001b[39m2022\u001b[39;49m,numFeat,numOut)\n\u001b[0;32m      6\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(train_data, batch_size\u001b[39m=\u001b[39mbatchSize,drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m test_data \u001b[39m=\u001b[39m dataSetAll(\u001b[39m2022\u001b[39m,\u001b[39m2100\u001b[39m,numFeat,numOut)\n",
      "Cell \u001b[1;32mIn [11], line 5\u001b[0m, in \u001b[0;36mdataSetAll.__init__\u001b[1;34m(self, yearLow, yearHigh, numFeat, numOut)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, yearLow, yearHigh,numFeat,numOut):\n\u001b[0;32m      4\u001b[0m     \u001b[39m#import data from CSV\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mcase\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mILINet.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[(yearLow \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mYEAR\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mYEAR\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m yearHigh)][[\u001b[39m\"\u001b[39m\u001b[39mILITOTAL\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m WEIGHTED ILI\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mTOTAL PATIENTS\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumFeat \u001b[39m=\u001b[39m numFeat \u001b[39m#------------------------\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\case\\\\ILINet.csv'"
     ]
    }
   ],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 4\n",
    "batchSize = 64\n",
    "train_data = dataSetAll(2020,2022,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batchSize,drop_last=False,shuffle=True)\n",
    "\n",
    "test_data = dataSetAll(2022,2100,numFeat,numOut)\n",
    "test_dataloader = DataLoader(train_data, batch_size=batchSize,drop_last=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 3\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 32\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,numLayers,numOut,sequenceLength,future=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.numOut = numOut\n",
    "        self.future = future\n",
    "        self.inputSize = inputSize\n",
    "        # print(batchSize,sequenceLength,inputSize)\n",
    "        # self.LSTM = nn.LSTM(inputSize,hiddenSize,numLayers,batch_first=True)\n",
    "        self.rnn = nn.RNNCell(inputSize,hiddenSize)\n",
    "        # self.rnn2 = nn.RNNCell(1,hiddenSize,nonlinearity='tanh')\n",
    "        self.fc = nn.Linear(hiddenSize,inputSize)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        nSamples = x.size(0)\n",
    "        outputs = torch.zeros([nSamples,4,self.inputSize])\n",
    "        h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        h_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "\n",
    "        for input in x.split(1,dim=1):\n",
    "            # print(input[:,0,:].size())\n",
    "            h_1 = self.rnn(input[:,0,:], h_1)\n",
    "            out = self.fc(h_1)\n",
    "        outputs[:,0] = out\n",
    "            # h_2 = h_1\n",
    "        for i in range(self.numOut-1):\n",
    "            h_1 = self.rnn(out, h_1)\n",
    "            out = self.fc(h_1)\n",
    "            outputs[:,i+1] = out\n",
    "\n",
    "        # outputs = torch.as_tensor(outputs)\n",
    "        return outputs\n",
    "\n",
    "model = RNN(inputSize,hiddenSize,numLayers,numOut,sequenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(X.size())\n",
    "        # X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        # break\n",
    "        # print(pred.size())\n",
    "        # print(y.size())\n",
    "        # print(\"pred\",pred.size())\n",
    "        # print(\"Y\",y.size())\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 0.023237  [    0/   91]\n",
      "loss(1): 0.014270  [    0/   91]\n",
      "loss(2): 0.007968  [    0/   91]\n",
      "loss(3): 0.003748  [    0/   91]\n",
      "loss(4): 0.001439  [    0/   91]\n",
      "loss(5): 0.000812  [    0/   91]\n",
      "loss(6): 0.001566  [    0/   91]\n",
      "loss(7): 0.002360  [    0/   91]\n",
      "loss(8): 0.002558  [    0/   91]\n",
      "loss(9): 0.001997  [    0/   91]\n",
      "loss(10): 0.001457  [    0/   91]\n",
      "loss(11): 0.000901  [    0/   91]\n",
      "loss(12): 0.000753  [    0/   91]\n",
      "loss(13): 0.000787  [    0/   91]\n",
      "loss(14): 0.000945  [    0/   91]\n",
      "loss(15): 0.000960  [    0/   91]\n",
      "loss(16): 0.000980  [    0/   91]\n",
      "loss(17): 0.001054  [    0/   91]\n",
      "loss(18): 0.000906  [    0/   91]\n",
      "loss(19): 0.000813  [    0/   91]\n",
      "loss(20): 0.000610  [    0/   91]\n",
      "loss(21): 0.000548  [    0/   91]\n",
      "loss(22): 0.000608  [    0/   91]\n",
      "loss(23): 0.000760  [    0/   91]\n",
      "loss(24): 0.000775  [    0/   91]\n",
      "loss(25): 0.000642  [    0/   91]\n",
      "loss(26): 0.000641  [    0/   91]\n",
      "loss(27): 0.000794  [    0/   91]\n",
      "loss(28): 0.000699  [    0/   91]\n",
      "loss(29): 0.000722  [    0/   91]\n",
      "loss(30): 0.000731  [    0/   91]\n",
      "loss(31): 0.000663  [    0/   91]\n",
      "loss(32): 0.000764  [    0/   91]\n",
      "loss(33): 0.000519  [    0/   91]\n",
      "loss(34): 0.000509  [    0/   91]\n",
      "loss(35): 0.000510  [    0/   91]\n",
      "loss(36): 0.000736  [    0/   91]\n",
      "loss(37): 0.000530  [    0/   91]\n",
      "loss(38): 0.000778  [    0/   91]\n",
      "loss(39): 0.000724  [    0/   91]\n",
      "loss(40): 0.000622  [    0/   91]\n",
      "loss(41): 0.000705  [    0/   91]\n",
      "loss(42): 0.000514  [    0/   91]\n",
      "loss(43): 0.000453  [    0/   91]\n",
      "loss(44): 0.000478  [    0/   91]\n",
      "loss(45): 0.000675  [    0/   91]\n",
      "loss(46): 0.000414  [    0/   91]\n",
      "loss(47): 0.000540  [    0/   91]\n",
      "loss(48): 0.000623  [    0/   91]\n",
      "loss(49): 0.000561  [    0/   91]\n",
      "loss(50): 0.000565  [    0/   91]\n",
      "loss(51): 0.000619  [    0/   91]\n",
      "loss(52): 0.000486  [    0/   91]\n",
      "loss(53): 0.000632  [    0/   91]\n",
      "loss(54): 0.000652  [    0/   91]\n",
      "loss(55): 0.000626  [    0/   91]\n",
      "loss(56): 0.000459  [    0/   91]\n",
      "loss(57): 0.000566  [    0/   91]\n",
      "loss(58): 0.000536  [    0/   91]\n",
      "loss(59): 0.000605  [    0/   91]\n",
      "loss(60): 0.000631  [    0/   91]\n",
      "loss(61): 0.000551  [    0/   91]\n",
      "loss(62): 0.000613  [    0/   91]\n",
      "loss(63): 0.000555  [    0/   91]\n",
      "loss(64): 0.000588  [    0/   91]\n",
      "loss(65): 0.000493  [    0/   91]\n",
      "loss(66): 0.000425  [    0/   91]\n",
      "loss(67): 0.000427  [    0/   91]\n",
      "loss(68): 0.000497  [    0/   91]\n",
      "loss(69): 0.000436  [    0/   91]\n",
      "loss(70): 0.000533  [    0/   91]\n",
      "loss(71): 0.000443  [    0/   91]\n",
      "loss(72): 0.000621  [    0/   91]\n",
      "loss(73): 0.000575  [    0/   91]\n",
      "loss(74): 0.000543  [    0/   91]\n",
      "loss(75): 0.000496  [    0/   91]\n",
      "loss(76): 0.000391  [    0/   91]\n",
      "loss(77): 0.000573  [    0/   91]\n",
      "loss(78): 0.000420  [    0/   91]\n",
      "loss(79): 0.000449  [    0/   91]\n",
      "loss(80): 0.000528  [    0/   91]\n",
      "loss(81): 0.000447  [    0/   91]\n",
      "loss(82): 0.000523  [    0/   91]\n",
      "loss(83): 0.000403  [    0/   91]\n",
      "loss(84): 0.000499  [    0/   91]\n",
      "loss(85): 0.000447  [    0/   91]\n",
      "loss(86): 0.000514  [    0/   91]\n",
      "loss(87): 0.000499  [    0/   91]\n",
      "loss(88): 0.000474  [    0/   91]\n",
      "loss(89): 0.000451  [    0/   91]\n",
      "loss(90): 0.000401  [    0/   91]\n",
      "loss(91): 0.000477  [    0/   91]\n",
      "loss(92): 0.000451  [    0/   91]\n",
      "loss(93): 0.000522  [    0/   91]\n",
      "loss(94): 0.000514  [    0/   91]\n",
      "loss(95): 0.000438  [    0/   91]\n",
      "loss(96): 0.000410  [    0/   91]\n",
      "loss(97): 0.000446  [    0/   91]\n",
      "loss(98): 0.000427  [    0/   91]\n",
      "loss(99): 0.000425  [    0/   91]\n",
      "loss(100): 0.000429  [    0/   91]\n",
      "loss(101): 0.000504  [    0/   91]\n",
      "loss(102): 0.000479  [    0/   91]\n",
      "loss(103): 0.000439  [    0/   91]\n",
      "loss(104): 0.000448  [    0/   91]\n",
      "loss(105): 0.000385  [    0/   91]\n",
      "loss(106): 0.000413  [    0/   91]\n",
      "loss(107): 0.000343  [    0/   91]\n",
      "loss(108): 0.000397  [    0/   91]\n",
      "loss(109): 0.000414  [    0/   91]\n",
      "loss(110): 0.000432  [    0/   91]\n",
      "loss(111): 0.000440  [    0/   91]\n",
      "loss(112): 0.000334  [    0/   91]\n",
      "loss(113): 0.000437  [    0/   91]\n",
      "loss(114): 0.000430  [    0/   91]\n",
      "loss(115): 0.000355  [    0/   91]\n",
      "loss(116): 0.000399  [    0/   91]\n",
      "loss(117): 0.000390  [    0/   91]\n",
      "loss(118): 0.000399  [    0/   91]\n",
      "loss(119): 0.000392  [    0/   91]\n",
      "loss(120): 0.000382  [    0/   91]\n",
      "loss(121): 0.000408  [    0/   91]\n",
      "loss(122): 0.000381  [    0/   91]\n",
      "loss(123): 0.000317  [    0/   91]\n",
      "loss(124): 0.000347  [    0/   91]\n",
      "loss(125): 0.000299  [    0/   91]\n",
      "loss(126): 0.000384  [    0/   91]\n",
      "loss(127): 0.000355  [    0/   91]\n",
      "loss(128): 0.000349  [    0/   91]\n",
      "loss(129): 0.000272  [    0/   91]\n",
      "loss(130): 0.000293  [    0/   91]\n",
      "loss(131): 0.000255  [    0/   91]\n",
      "loss(132): 0.000350  [    0/   91]\n",
      "loss(133): 0.000293  [    0/   91]\n",
      "loss(134): 0.000299  [    0/   91]\n",
      "loss(135): 0.000330  [    0/   91]\n",
      "loss(136): 0.000274  [    0/   91]\n",
      "loss(137): 0.000234  [    0/   91]\n",
      "loss(138): 0.000315  [    0/   91]\n",
      "loss(139): 0.000326  [    0/   91]\n",
      "loss(140): 0.000307  [    0/   91]\n",
      "loss(141): 0.000274  [    0/   91]\n",
      "loss(142): 0.000292  [    0/   91]\n",
      "loss(143): 0.000314  [    0/   91]\n",
      "loss(144): 0.000280  [    0/   91]\n",
      "loss(145): 0.000270  [    0/   91]\n",
      "loss(146): 0.000310  [    0/   91]\n",
      "loss(147): 0.000252  [    0/   91]\n",
      "loss(148): 0.000304  [    0/   91]\n",
      "loss(149): 0.000236  [    0/   91]\n",
      "loss(150): 0.000234  [    0/   91]\n",
      "loss(151): 0.000250  [    0/   91]\n",
      "loss(152): 0.000279  [    0/   91]\n",
      "loss(153): 0.000233  [    0/   91]\n",
      "loss(154): 0.000260  [    0/   91]\n",
      "loss(155): 0.000239  [    0/   91]\n",
      "loss(156): 0.000299  [    0/   91]\n",
      "loss(157): 0.000233  [    0/   91]\n",
      "loss(158): 0.000185  [    0/   91]\n",
      "loss(159): 0.000254  [    0/   91]\n",
      "loss(160): 0.000279  [    0/   91]\n",
      "loss(161): 0.000242  [    0/   91]\n",
      "loss(162): 0.000221  [    0/   91]\n",
      "loss(163): 0.000246  [    0/   91]\n",
      "loss(164): 0.000172  [    0/   91]\n",
      "loss(165): 0.000219  [    0/   91]\n",
      "loss(166): 0.000273  [    0/   91]\n",
      "loss(167): 0.000272  [    0/   91]\n",
      "loss(168): 0.000222  [    0/   91]\n",
      "loss(169): 0.000173  [    0/   91]\n",
      "loss(170): 0.000233  [    0/   91]\n",
      "loss(171): 0.000231  [    0/   91]\n",
      "loss(172): 0.000271  [    0/   91]\n",
      "loss(173): 0.000186  [    0/   91]\n",
      "loss(174): 0.000253  [    0/   91]\n",
      "loss(175): 0.000247  [    0/   91]\n",
      "loss(176): 0.000206  [    0/   91]\n",
      "loss(177): 0.000236  [    0/   91]\n",
      "loss(178): 0.000247  [    0/   91]\n",
      "loss(179): 0.000251  [    0/   91]\n",
      "loss(180): 0.000218  [    0/   91]\n",
      "loss(181): 0.000239  [    0/   91]\n",
      "loss(182): 0.000241  [    0/   91]\n",
      "loss(183): 0.000166  [    0/   91]\n",
      "loss(184): 0.000246  [    0/   91]\n",
      "loss(185): 0.000245  [    0/   91]\n",
      "loss(186): 0.000276  [    0/   91]\n",
      "loss(187): 0.000178  [    0/   91]\n",
      "loss(188): 0.000286  [    0/   91]\n",
      "loss(189): 0.000202  [    0/   91]\n",
      "loss(190): 0.000264  [    0/   91]\n",
      "loss(191): 0.000235  [    0/   91]\n",
      "loss(192): 0.000217  [    0/   91]\n",
      "loss(193): 0.000238  [    0/   91]\n",
      "loss(194): 0.000199  [    0/   91]\n",
      "loss(195): 0.000215  [    0/   91]\n",
      "loss(196): 0.000238  [    0/   91]\n",
      "loss(197): 0.000205  [    0/   91]\n",
      "loss(198): 0.000184  [    0/   91]\n",
      "loss(199): 0.000201  [    0/   91]\n",
      "loss(200): 0.000201  [    0/   91]\n",
      "loss(201): 0.000197  [    0/   91]\n",
      "loss(202): 0.000210  [    0/   91]\n",
      "loss(203): 0.000199  [    0/   91]\n",
      "loss(204): 0.000178  [    0/   91]\n",
      "loss(205): 0.000210  [    0/   91]\n",
      "loss(206): 0.000193  [    0/   91]\n",
      "loss(207): 0.000245  [    0/   91]\n",
      "loss(208): 0.000240  [    0/   91]\n",
      "loss(209): 0.000205  [    0/   91]\n",
      "loss(210): 0.000218  [    0/   91]\n",
      "loss(211): 0.000179  [    0/   91]\n",
      "loss(212): 0.000200  [    0/   91]\n",
      "loss(213): 0.000222  [    0/   91]\n",
      "loss(214): 0.000176  [    0/   91]\n",
      "loss(215): 0.000222  [    0/   91]\n",
      "loss(216): 0.000238  [    0/   91]\n",
      "loss(217): 0.000266  [    0/   91]\n",
      "loss(218): 0.000207  [    0/   91]\n",
      "loss(219): 0.000178  [    0/   91]\n",
      "loss(220): 0.000217  [    0/   91]\n",
      "loss(221): 0.000182  [    0/   91]\n",
      "loss(222): 0.000184  [    0/   91]\n",
      "loss(223): 0.000191  [    0/   91]\n",
      "loss(224): 0.000207  [    0/   91]\n",
      "loss(225): 0.000191  [    0/   91]\n",
      "loss(226): 0.000234  [    0/   91]\n",
      "loss(227): 0.000161  [    0/   91]\n",
      "loss(228): 0.000152  [    0/   91]\n",
      "loss(229): 0.000184  [    0/   91]\n",
      "loss(230): 0.000163  [    0/   91]\n",
      "loss(231): 0.000213  [    0/   91]\n",
      "loss(232): 0.000164  [    0/   91]\n",
      "loss(233): 0.000186  [    0/   91]\n",
      "loss(234): 0.000214  [    0/   91]\n",
      "loss(235): 0.000157  [    0/   91]\n",
      "loss(236): 0.000182  [    0/   91]\n",
      "loss(237): 0.000180  [    0/   91]\n",
      "loss(238): 0.000159  [    0/   91]\n",
      "loss(239): 0.000185  [    0/   91]\n",
      "loss(240): 0.000190  [    0/   91]\n",
      "loss(241): 0.000174  [    0/   91]\n",
      "loss(242): 0.000162  [    0/   91]\n",
      "loss(243): 0.000167  [    0/   91]\n",
      "loss(244): 0.000172  [    0/   91]\n",
      "loss(245): 0.000201  [    0/   91]\n",
      "loss(246): 0.000214  [    0/   91]\n",
      "loss(247): 0.000188  [    0/   91]\n",
      "loss(248): 0.000198  [    0/   91]\n",
      "loss(249): 0.000223  [    0/   91]\n",
      "loss(250): 0.000206  [    0/   91]\n",
      "loss(251): 0.000163  [    0/   91]\n",
      "loss(252): 0.000225  [    0/   91]\n",
      "loss(253): 0.000199  [    0/   91]\n",
      "loss(254): 0.000204  [    0/   91]\n",
      "loss(255): 0.000176  [    0/   91]\n",
      "loss(256): 0.000212  [    0/   91]\n",
      "loss(257): 0.000165  [    0/   91]\n",
      "loss(258): 0.000176  [    0/   91]\n",
      "loss(259): 0.000159  [    0/   91]\n",
      "loss(260): 0.000208  [    0/   91]\n",
      "loss(261): 0.000218  [    0/   91]\n",
      "loss(262): 0.000208  [    0/   91]\n",
      "loss(263): 0.000199  [    0/   91]\n",
      "loss(264): 0.000204  [    0/   91]\n",
      "loss(265): 0.000175  [    0/   91]\n",
      "loss(266): 0.000161  [    0/   91]\n",
      "loss(267): 0.000164  [    0/   91]\n",
      "loss(268): 0.000126  [    0/   91]\n",
      "loss(269): 0.000196  [    0/   91]\n",
      "loss(270): 0.000190  [    0/   91]\n",
      "loss(271): 0.000182  [    0/   91]\n",
      "loss(272): 0.000213  [    0/   91]\n",
      "loss(273): 0.000120  [    0/   91]\n",
      "loss(274): 0.000207  [    0/   91]\n",
      "loss(275): 0.000179  [    0/   91]\n",
      "loss(276): 0.000207  [    0/   91]\n",
      "loss(277): 0.000115  [    0/   91]\n",
      "loss(278): 0.000225  [    0/   91]\n",
      "loss(279): 0.000201  [    0/   91]\n",
      "loss(280): 0.000193  [    0/   91]\n",
      "loss(281): 0.000265  [    0/   91]\n",
      "loss(282): 0.000172  [    0/   91]\n",
      "loss(283): 0.000144  [    0/   91]\n",
      "loss(284): 0.000190  [    0/   91]\n",
      "loss(285): 0.000156  [    0/   91]\n",
      "loss(286): 0.000200  [    0/   91]\n",
      "loss(287): 0.000190  [    0/   91]\n",
      "loss(288): 0.000215  [    0/   91]\n",
      "loss(289): 0.000185  [    0/   91]\n",
      "loss(290): 0.000166  [    0/   91]\n",
      "loss(291): 0.000198  [    0/   91]\n",
      "loss(292): 0.000120  [    0/   91]\n",
      "loss(293): 0.000195  [    0/   91]\n",
      "loss(294): 0.000170  [    0/   91]\n",
      "loss(295): 0.000198  [    0/   91]\n",
      "loss(296): 0.000179  [    0/   91]\n",
      "loss(297): 0.000190  [    0/   91]\n",
      "loss(298): 0.000200  [    0/   91]\n",
      "loss(299): 0.000165  [    0/   91]\n",
      "loss(300): 0.000164  [    0/   91]\n",
      "loss(301): 0.000144  [    0/   91]\n",
      "loss(302): 0.000184  [    0/   91]\n",
      "loss(303): 0.000162  [    0/   91]\n",
      "loss(304): 0.000159  [    0/   91]\n",
      "loss(305): 0.000170  [    0/   91]\n",
      "loss(306): 0.000177  [    0/   91]\n",
      "loss(307): 0.000178  [    0/   91]\n",
      "loss(308): 0.000173  [    0/   91]\n",
      "loss(309): 0.000191  [    0/   91]\n",
      "loss(310): 0.000189  [    0/   91]\n",
      "loss(311): 0.000158  [    0/   91]\n",
      "loss(312): 0.000143  [    0/   91]\n",
      "loss(313): 0.000159  [    0/   91]\n",
      "loss(314): 0.000192  [    0/   91]\n",
      "loss(315): 0.000168  [    0/   91]\n",
      "loss(316): 0.000204  [    0/   91]\n",
      "loss(317): 0.000172  [    0/   91]\n",
      "loss(318): 0.000159  [    0/   91]\n",
      "loss(319): 0.000152  [    0/   91]\n",
      "loss(320): 0.000184  [    0/   91]\n",
      "loss(321): 0.000140  [    0/   91]\n",
      "loss(322): 0.000192  [    0/   91]\n",
      "loss(323): 0.000172  [    0/   91]\n",
      "loss(324): 0.000129  [    0/   91]\n",
      "loss(325): 0.000096  [    0/   91]\n",
      "loss(326): 0.000165  [    0/   91]\n",
      "loss(327): 0.000152  [    0/   91]\n",
      "loss(328): 0.000150  [    0/   91]\n",
      "loss(329): 0.000156  [    0/   91]\n",
      "loss(330): 0.000179  [    0/   91]\n",
      "loss(331): 0.000162  [    0/   91]\n",
      "loss(332): 0.000150  [    0/   91]\n",
      "loss(333): 0.000138  [    0/   91]\n",
      "loss(334): 0.000165  [    0/   91]\n",
      "loss(335): 0.000178  [    0/   91]\n",
      "loss(336): 0.000136  [    0/   91]\n",
      "loss(337): 0.000140  [    0/   91]\n",
      "loss(338): 0.000209  [    0/   91]\n",
      "loss(339): 0.000203  [    0/   91]\n",
      "loss(340): 0.000175  [    0/   91]\n",
      "loss(341): 0.000163  [    0/   91]\n",
      "loss(342): 0.000175  [    0/   91]\n",
      "loss(343): 0.000181  [    0/   91]\n",
      "loss(344): 0.000190  [    0/   91]\n",
      "loss(345): 0.000164  [    0/   91]\n",
      "loss(346): 0.000193  [    0/   91]\n",
      "loss(347): 0.000195  [    0/   91]\n",
      "loss(348): 0.000114  [    0/   91]\n",
      "loss(349): 0.000182  [    0/   91]\n",
      "loss(350): 0.000150  [    0/   91]\n",
      "loss(351): 0.000173  [    0/   91]\n",
      "loss(352): 0.000175  [    0/   91]\n",
      "loss(353): 0.000171  [    0/   91]\n",
      "loss(354): 0.000175  [    0/   91]\n",
      "loss(355): 0.000130  [    0/   91]\n",
      "loss(356): 0.000143  [    0/   91]\n",
      "loss(357): 0.000162  [    0/   91]\n",
      "loss(358): 0.000178  [    0/   91]\n",
      "loss(359): 0.000173  [    0/   91]\n",
      "loss(360): 0.000179  [    0/   91]\n",
      "loss(361): 0.000165  [    0/   91]\n",
      "loss(362): 0.000169  [    0/   91]\n",
      "loss(363): 0.000154  [    0/   91]\n",
      "loss(364): 0.000121  [    0/   91]\n",
      "loss(365): 0.000166  [    0/   91]\n",
      "loss(366): 0.000128  [    0/   91]\n",
      "loss(367): 0.000171  [    0/   91]\n",
      "loss(368): 0.000173  [    0/   91]\n",
      "loss(369): 0.000142  [    0/   91]\n",
      "loss(370): 0.000161  [    0/   91]\n",
      "loss(371): 0.000166  [    0/   91]\n",
      "loss(372): 0.000189  [    0/   91]\n",
      "loss(373): 0.000150  [    0/   91]\n",
      "loss(374): 0.000176  [    0/   91]\n",
      "loss(375): 0.000121  [    0/   91]\n",
      "loss(376): 0.000115  [    0/   91]\n",
      "loss(377): 0.000178  [    0/   91]\n",
      "loss(378): 0.000170  [    0/   91]\n",
      "loss(379): 0.000167  [    0/   91]\n",
      "loss(380): 0.000135  [    0/   91]\n",
      "loss(381): 0.000146  [    0/   91]\n",
      "loss(382): 0.000170  [    0/   91]\n",
      "loss(383): 0.000158  [    0/   91]\n",
      "loss(384): 0.000145  [    0/   91]\n",
      "loss(385): 0.000180  [    0/   91]\n",
      "loss(386): 0.000116  [    0/   91]\n",
      "loss(387): 0.000168  [    0/   91]\n",
      "loss(388): 0.000144  [    0/   91]\n",
      "loss(389): 0.000177  [    0/   91]\n",
      "loss(390): 0.000148  [    0/   91]\n",
      "loss(391): 0.000163  [    0/   91]\n",
      "loss(392): 0.000175  [    0/   91]\n",
      "loss(393): 0.000172  [    0/   91]\n",
      "loss(394): 0.000132  [    0/   91]\n",
      "loss(395): 0.000174  [    0/   91]\n",
      "loss(396): 0.000150  [    0/   91]\n",
      "loss(397): 0.000155  [    0/   91]\n",
      "loss(398): 0.000132  [    0/   91]\n",
      "loss(399): 0.000153  [    0/   91]\n",
      "loss(400): 0.000091  [    0/   91]\n",
      "loss(401): 0.000158  [    0/   91]\n",
      "loss(402): 0.000167  [    0/   91]\n",
      "loss(403): 0.000113  [    0/   91]\n",
      "loss(404): 0.000200  [    0/   91]\n",
      "loss(405): 0.000187  [    0/   91]\n",
      "loss(406): 0.000173  [    0/   91]\n",
      "loss(407): 0.000112  [    0/   91]\n",
      "loss(408): 0.000133  [    0/   91]\n",
      "loss(409): 0.000148  [    0/   91]\n",
      "loss(410): 0.000159  [    0/   91]\n",
      "loss(411): 0.000171  [    0/   91]\n",
      "loss(412): 0.000143  [    0/   91]\n",
      "loss(413): 0.000147  [    0/   91]\n",
      "loss(414): 0.000104  [    0/   91]\n",
      "loss(415): 0.000142  [    0/   91]\n",
      "loss(416): 0.000151  [    0/   91]\n",
      "loss(417): 0.000180  [    0/   91]\n",
      "loss(418): 0.000131  [    0/   91]\n",
      "loss(419): 0.000145  [    0/   91]\n",
      "loss(420): 0.000168  [    0/   91]\n",
      "loss(421): 0.000208  [    0/   91]\n",
      "loss(422): 0.000158  [    0/   91]\n",
      "loss(423): 0.000132  [    0/   91]\n",
      "loss(424): 0.000174  [    0/   91]\n",
      "loss(425): 0.000148  [    0/   91]\n",
      "loss(426): 0.000182  [    0/   91]\n",
      "loss(427): 0.000158  [    0/   91]\n",
      "loss(428): 0.000120  [    0/   91]\n",
      "loss(429): 0.000149  [    0/   91]\n",
      "loss(430): 0.000130  [    0/   91]\n",
      "loss(431): 0.000163  [    0/   91]\n",
      "loss(432): 0.000138  [    0/   91]\n",
      "loss(433): 0.000135  [    0/   91]\n",
      "loss(434): 0.000127  [    0/   91]\n",
      "loss(435): 0.000102  [    0/   91]\n",
      "loss(436): 0.000135  [    0/   91]\n",
      "loss(437): 0.000130  [    0/   91]\n",
      "loss(438): 0.000152  [    0/   91]\n",
      "loss(439): 0.000123  [    0/   91]\n",
      "loss(440): 0.000154  [    0/   91]\n",
      "loss(441): 0.000183  [    0/   91]\n",
      "loss(442): 0.000145  [    0/   91]\n",
      "loss(443): 0.000117  [    0/   91]\n",
      "loss(444): 0.000125  [    0/   91]\n",
      "loss(445): 0.000104  [    0/   91]\n",
      "loss(446): 0.000124  [    0/   91]\n",
      "loss(447): 0.000135  [    0/   91]\n",
      "loss(448): 0.000123  [    0/   91]\n",
      "loss(449): 0.000131  [    0/   91]\n",
      "loss(450): 0.000122  [    0/   91]\n",
      "loss(451): 0.000152  [    0/   91]\n",
      "loss(452): 0.000157  [    0/   91]\n",
      "loss(453): 0.000131  [    0/   91]\n",
      "loss(454): 0.000142  [    0/   91]\n",
      "loss(455): 0.000168  [    0/   91]\n",
      "loss(456): 0.000151  [    0/   91]\n",
      "loss(457): 0.000117  [    0/   91]\n",
      "loss(458): 0.000165  [    0/   91]\n",
      "loss(459): 0.000140  [    0/   91]\n",
      "loss(460): 0.000114  [    0/   91]\n",
      "loss(461): 0.000108  [    0/   91]\n",
      "loss(462): 0.000139  [    0/   91]\n",
      "loss(463): 0.000150  [    0/   91]\n",
      "loss(464): 0.000125  [    0/   91]\n",
      "loss(465): 0.000136  [    0/   91]\n",
      "loss(466): 0.000137  [    0/   91]\n",
      "loss(467): 0.000137  [    0/   91]\n",
      "loss(468): 0.000134  [    0/   91]\n",
      "loss(469): 0.000147  [    0/   91]\n",
      "loss(470): 0.000107  [    0/   91]\n",
      "loss(471): 0.000135  [    0/   91]\n",
      "loss(472): 0.000129  [    0/   91]\n",
      "loss(473): 0.000154  [    0/   91]\n",
      "loss(474): 0.000166  [    0/   91]\n",
      "loss(475): 0.000124  [    0/   91]\n",
      "loss(476): 0.000118  [    0/   91]\n",
      "loss(477): 0.000117  [    0/   91]\n",
      "loss(478): 0.000125  [    0/   91]\n",
      "loss(479): 0.000110  [    0/   91]\n",
      "loss(480): 0.000129  [    0/   91]\n",
      "loss(481): 0.000156  [    0/   91]\n",
      "loss(482): 0.000111  [    0/   91]\n",
      "loss(483): 0.000153  [    0/   91]\n",
      "loss(484): 0.000121  [    0/   91]\n",
      "loss(485): 0.000161  [    0/   91]\n",
      "loss(486): 0.000123  [    0/   91]\n",
      "loss(487): 0.000117  [    0/   91]\n",
      "loss(488): 0.000096  [    0/   91]\n",
      "loss(489): 0.000145  [    0/   91]\n",
      "loss(490): 0.000123  [    0/   91]\n",
      "loss(491): 0.000135  [    0/   91]\n",
      "loss(492): 0.000166  [    0/   91]\n",
      "loss(493): 0.000164  [    0/   91]\n",
      "loss(494): 0.000175  [    0/   91]\n",
      "loss(495): 0.000092  [    0/   91]\n",
      "loss(496): 0.000120  [    0/   91]\n",
      "loss(497): 0.000138  [    0/   91]\n",
      "loss(498): 0.000114  [    0/   91]\n",
      "loss(499): 0.000143  [    0/   91]\n",
      "loss(500): 0.000105  [    0/   91]\n",
      "loss(501): 0.000135  [    0/   91]\n",
      "loss(502): 0.000131  [    0/   91]\n",
      "loss(503): 0.000167  [    0/   91]\n",
      "loss(504): 0.000096  [    0/   91]\n",
      "loss(505): 0.000140  [    0/   91]\n",
      "loss(506): 0.000119  [    0/   91]\n",
      "loss(507): 0.000107  [    0/   91]\n",
      "loss(508): 0.000143  [    0/   91]\n",
      "loss(509): 0.000113  [    0/   91]\n",
      "loss(510): 0.000133  [    0/   91]\n",
      "loss(511): 0.000139  [    0/   91]\n",
      "loss(512): 0.000137  [    0/   91]\n",
      "loss(513): 0.000130  [    0/   91]\n",
      "loss(514): 0.000126  [    0/   91]\n",
      "loss(515): 0.000120  [    0/   91]\n",
      "loss(516): 0.000123  [    0/   91]\n",
      "loss(517): 0.000120  [    0/   91]\n",
      "loss(518): 0.000111  [    0/   91]\n",
      "loss(519): 0.000090  [    0/   91]\n",
      "loss(520): 0.000141  [    0/   91]\n",
      "loss(521): 0.000132  [    0/   91]\n",
      "loss(522): 0.000151  [    0/   91]\n",
      "loss(523): 0.000144  [    0/   91]\n",
      "loss(524): 0.000127  [    0/   91]\n",
      "loss(525): 0.000126  [    0/   91]\n",
      "loss(526): 0.000134  [    0/   91]\n",
      "loss(527): 0.000119  [    0/   91]\n",
      "loss(528): 0.000134  [    0/   91]\n",
      "loss(529): 0.000117  [    0/   91]\n",
      "loss(530): 0.000140  [    0/   91]\n",
      "loss(531): 0.000135  [    0/   91]\n",
      "loss(532): 0.000148  [    0/   91]\n",
      "loss(533): 0.000155  [    0/   91]\n",
      "loss(534): 0.000128  [    0/   91]\n",
      "loss(535): 0.000170  [    0/   91]\n",
      "loss(536): 0.000160  [    0/   91]\n",
      "loss(537): 0.000132  [    0/   91]\n",
      "loss(538): 0.000149  [    0/   91]\n",
      "loss(539): 0.000199  [    0/   91]\n",
      "loss(540): 0.000160  [    0/   91]\n",
      "loss(541): 0.000137  [    0/   91]\n",
      "loss(542): 0.000129  [    0/   91]\n",
      "loss(543): 0.000110  [    0/   91]\n",
      "loss(544): 0.000155  [    0/   91]\n",
      "loss(545): 0.000143  [    0/   91]\n",
      "loss(546): 0.000109  [    0/   91]\n",
      "loss(547): 0.000091  [    0/   91]\n",
      "loss(548): 0.000141  [    0/   91]\n",
      "loss(549): 0.000134  [    0/   91]\n",
      "loss(550): 0.000134  [    0/   91]\n",
      "loss(551): 0.000110  [    0/   91]\n",
      "loss(552): 0.000108  [    0/   91]\n",
      "loss(553): 0.000106  [    0/   91]\n",
      "loss(554): 0.000093  [    0/   91]\n",
      "loss(555): 0.000150  [    0/   91]\n",
      "loss(556): 0.000149  [    0/   91]\n",
      "loss(557): 0.000132  [    0/   91]\n",
      "loss(558): 0.000117  [    0/   91]\n",
      "loss(559): 0.000142  [    0/   91]\n",
      "loss(560): 0.000130  [    0/   91]\n",
      "loss(561): 0.000118  [    0/   91]\n",
      "loss(562): 0.000121  [    0/   91]\n",
      "loss(563): 0.000083  [    0/   91]\n",
      "loss(564): 0.000123  [    0/   91]\n",
      "loss(565): 0.000131  [    0/   91]\n",
      "loss(566): 0.000136  [    0/   91]\n",
      "loss(567): 0.000119  [    0/   91]\n",
      "loss(568): 0.000131  [    0/   91]\n",
      "loss(569): 0.000131  [    0/   91]\n",
      "loss(570): 0.000137  [    0/   91]\n",
      "loss(571): 0.000115  [    0/   91]\n",
      "loss(572): 0.000131  [    0/   91]\n",
      "loss(573): 0.000097  [    0/   91]\n",
      "loss(574): 0.000139  [    0/   91]\n",
      "loss(575): 0.000137  [    0/   91]\n",
      "loss(576): 0.000183  [    0/   91]\n",
      "loss(577): 0.000118  [    0/   91]\n",
      "loss(578): 0.000085  [    0/   91]\n",
      "loss(579): 0.000134  [    0/   91]\n",
      "loss(580): 0.000131  [    0/   91]\n",
      "loss(581): 0.000122  [    0/   91]\n",
      "loss(582): 0.000128  [    0/   91]\n",
      "loss(583): 0.000122  [    0/   91]\n",
      "loss(584): 0.000105  [    0/   91]\n",
      "loss(585): 0.000142  [    0/   91]\n",
      "loss(586): 0.000154  [    0/   91]\n",
      "loss(587): 0.000157  [    0/   91]\n",
      "loss(588): 0.000134  [    0/   91]\n",
      "loss(589): 0.000092  [    0/   91]\n",
      "loss(590): 0.000170  [    0/   91]\n",
      "loss(591): 0.000143  [    0/   91]\n",
      "loss(592): 0.000140  [    0/   91]\n",
      "loss(593): 0.000115  [    0/   91]\n",
      "loss(594): 0.000107  [    0/   91]\n",
      "loss(595): 0.000104  [    0/   91]\n",
      "loss(596): 0.000103  [    0/   91]\n",
      "loss(597): 0.000161  [    0/   91]\n",
      "loss(598): 0.000139  [    0/   91]\n",
      "loss(599): 0.000143  [    0/   91]\n",
      "loss(600): 0.000168  [    0/   91]\n",
      "loss(601): 0.000111  [    0/   91]\n",
      "loss(602): 0.000127  [    0/   91]\n",
      "loss(603): 0.000102  [    0/   91]\n",
      "loss(604): 0.000137  [    0/   91]\n",
      "loss(605): 0.000120  [    0/   91]\n",
      "loss(606): 0.000131  [    0/   91]\n",
      "loss(607): 0.000135  [    0/   91]\n",
      "loss(608): 0.000095  [    0/   91]\n",
      "loss(609): 0.000073  [    0/   91]\n",
      "loss(610): 0.000134  [    0/   91]\n",
      "loss(611): 0.000112  [    0/   91]\n",
      "loss(612): 0.000105  [    0/   91]\n",
      "loss(613): 0.000151  [    0/   91]\n",
      "loss(614): 0.000126  [    0/   91]\n",
      "loss(615): 0.000134  [    0/   91]\n",
      "loss(616): 0.000127  [    0/   91]\n",
      "loss(617): 0.000133  [    0/   91]\n",
      "loss(618): 0.000112  [    0/   91]\n",
      "loss(619): 0.000095  [    0/   91]\n",
      "loss(620): 0.000115  [    0/   91]\n",
      "loss(621): 0.000106  [    0/   91]\n",
      "loss(622): 0.000128  [    0/   91]\n",
      "loss(623): 0.000131  [    0/   91]\n",
      "loss(624): 0.000151  [    0/   91]\n",
      "loss(625): 0.000114  [    0/   91]\n",
      "loss(626): 0.000153  [    0/   91]\n",
      "loss(627): 0.000145  [    0/   91]\n",
      "loss(628): 0.000104  [    0/   91]\n",
      "loss(629): 0.000096  [    0/   91]\n",
      "loss(630): 0.000109  [    0/   91]\n",
      "loss(631): 0.000118  [    0/   91]\n",
      "loss(632): 0.000138  [    0/   91]\n",
      "loss(633): 0.000148  [    0/   91]\n",
      "loss(634): 0.000120  [    0/   91]\n",
      "loss(635): 0.000132  [    0/   91]\n",
      "loss(636): 0.000134  [    0/   91]\n",
      "loss(637): 0.000116  [    0/   91]\n",
      "loss(638): 0.000134  [    0/   91]\n",
      "loss(639): 0.000134  [    0/   91]\n",
      "loss(640): 0.000129  [    0/   91]\n",
      "loss(641): 0.000143  [    0/   91]\n",
      "loss(642): 0.000127  [    0/   91]\n",
      "loss(643): 0.000122  [    0/   91]\n",
      "loss(644): 0.000168  [    0/   91]\n",
      "loss(645): 0.000128  [    0/   91]\n",
      "loss(646): 0.000163  [    0/   91]\n",
      "loss(647): 0.000175  [    0/   91]\n",
      "loss(648): 0.000144  [    0/   91]\n",
      "loss(649): 0.000120  [    0/   91]\n",
      "loss(650): 0.000115  [    0/   91]\n",
      "loss(651): 0.000141  [    0/   91]\n",
      "loss(652): 0.000119  [    0/   91]\n",
      "loss(653): 0.000118  [    0/   91]\n",
      "loss(654): 0.000121  [    0/   91]\n",
      "loss(655): 0.000146  [    0/   91]\n",
      "loss(656): 0.000119  [    0/   91]\n",
      "loss(657): 0.000144  [    0/   91]\n",
      "loss(658): 0.000101  [    0/   91]\n",
      "loss(659): 0.000104  [    0/   91]\n",
      "loss(660): 0.000105  [    0/   91]\n",
      "loss(661): 0.000120  [    0/   91]\n",
      "loss(662): 0.000089  [    0/   91]\n",
      "loss(663): 0.000086  [    0/   91]\n",
      "loss(664): 0.000140  [    0/   91]\n",
      "loss(665): 0.000096  [    0/   91]\n",
      "loss(666): 0.000117  [    0/   91]\n",
      "loss(667): 0.000087  [    0/   91]\n",
      "loss(668): 0.000108  [    0/   91]\n",
      "loss(669): 0.000128  [    0/   91]\n",
      "loss(670): 0.000115  [    0/   91]\n",
      "loss(671): 0.000094  [    0/   91]\n",
      "loss(672): 0.000123  [    0/   91]\n",
      "loss(673): 0.000119  [    0/   91]\n",
      "loss(674): 0.000100  [    0/   91]\n",
      "loss(675): 0.000137  [    0/   91]\n",
      "loss(676): 0.000066  [    0/   91]\n",
      "loss(677): 0.000105  [    0/   91]\n",
      "loss(678): 0.000126  [    0/   91]\n",
      "loss(679): 0.000122  [    0/   91]\n",
      "loss(680): 0.000122  [    0/   91]\n",
      "loss(681): 0.000079  [    0/   91]\n",
      "loss(682): 0.000129  [    0/   91]\n",
      "loss(683): 0.000131  [    0/   91]\n",
      "loss(684): 0.000110  [    0/   91]\n",
      "loss(685): 0.000122  [    0/   91]\n",
      "loss(686): 0.000104  [    0/   91]\n",
      "loss(687): 0.000131  [    0/   91]\n",
      "loss(688): 0.000107  [    0/   91]\n",
      "loss(689): 0.000107  [    0/   91]\n",
      "loss(690): 0.000110  [    0/   91]\n",
      "loss(691): 0.000133  [    0/   91]\n",
      "loss(692): 0.000125  [    0/   91]\n",
      "loss(693): 0.000078  [    0/   91]\n",
      "loss(694): 0.000106  [    0/   91]\n",
      "loss(695): 0.000098  [    0/   91]\n",
      "loss(696): 0.000169  [    0/   91]\n",
      "loss(697): 0.000106  [    0/   91]\n",
      "loss(698): 0.000100  [    0/   91]\n",
      "loss(699): 0.000134  [    0/   91]\n",
      "loss(700): 0.000124  [    0/   91]\n",
      "loss(701): 0.000117  [    0/   91]\n",
      "loss(702): 0.000129  [    0/   91]\n",
      "loss(703): 0.000134  [    0/   91]\n",
      "loss(704): 0.000117  [    0/   91]\n",
      "loss(705): 0.000173  [    0/   91]\n",
      "loss(706): 0.000104  [    0/   91]\n",
      "loss(707): 0.000099  [    0/   91]\n",
      "loss(708): 0.000130  [    0/   91]\n",
      "loss(709): 0.000127  [    0/   91]\n",
      "loss(710): 0.000082  [    0/   91]\n",
      "loss(711): 0.000125  [    0/   91]\n",
      "loss(712): 0.000111  [    0/   91]\n",
      "loss(713): 0.000101  [    0/   91]\n",
      "loss(714): 0.000139  [    0/   91]\n",
      "loss(715): 0.000095  [    0/   91]\n",
      "loss(716): 0.000087  [    0/   91]\n",
      "loss(717): 0.000129  [    0/   91]\n",
      "loss(718): 0.000110  [    0/   91]\n",
      "loss(719): 0.000128  [    0/   91]\n",
      "loss(720): 0.000128  [    0/   91]\n",
      "loss(721): 0.000089  [    0/   91]\n",
      "loss(722): 0.000124  [    0/   91]\n",
      "loss(723): 0.000102  [    0/   91]\n",
      "loss(724): 0.000109  [    0/   91]\n",
      "loss(725): 0.000115  [    0/   91]\n",
      "loss(726): 0.000125  [    0/   91]\n",
      "loss(727): 0.000108  [    0/   91]\n",
      "loss(728): 0.000099  [    0/   91]\n",
      "loss(729): 0.000109  [    0/   91]\n",
      "loss(730): 0.000116  [    0/   91]\n",
      "loss(731): 0.000094  [    0/   91]\n",
      "loss(732): 0.000118  [    0/   91]\n",
      "loss(733): 0.000095  [    0/   91]\n",
      "loss(734): 0.000119  [    0/   91]\n",
      "loss(735): 0.000100  [    0/   91]\n",
      "loss(736): 0.000114  [    0/   91]\n",
      "loss(737): 0.000095  [    0/   91]\n",
      "loss(738): 0.000103  [    0/   91]\n",
      "loss(739): 0.000106  [    0/   91]\n",
      "loss(740): 0.000108  [    0/   91]\n",
      "loss(741): 0.000105  [    0/   91]\n",
      "loss(742): 0.000122  [    0/   91]\n",
      "loss(743): 0.000119  [    0/   91]\n",
      "loss(744): 0.000083  [    0/   91]\n",
      "loss(745): 0.000105  [    0/   91]\n",
      "loss(746): 0.000101  [    0/   91]\n",
      "loss(747): 0.000110  [    0/   91]\n",
      "loss(748): 0.000129  [    0/   91]\n",
      "loss(749): 0.000079  [    0/   91]\n",
      "loss(750): 0.000115  [    0/   91]\n",
      "loss(751): 0.000105  [    0/   91]\n",
      "loss(752): 0.000094  [    0/   91]\n",
      "loss(753): 0.000131  [    0/   91]\n",
      "loss(754): 0.000144  [    0/   91]\n",
      "loss(755): 0.000140  [    0/   91]\n",
      "loss(756): 0.000132  [    0/   91]\n",
      "loss(757): 0.000107  [    0/   91]\n",
      "loss(758): 0.000117  [    0/   91]\n",
      "loss(759): 0.000100  [    0/   91]\n",
      "loss(760): 0.000145  [    0/   91]\n",
      "loss(761): 0.000113  [    0/   91]\n",
      "loss(762): 0.000110  [    0/   91]\n",
      "loss(763): 0.000127  [    0/   91]\n",
      "loss(764): 0.000118  [    0/   91]\n",
      "loss(765): 0.000087  [    0/   91]\n",
      "loss(766): 0.000120  [    0/   91]\n",
      "loss(767): 0.000116  [    0/   91]\n",
      "loss(768): 0.000105  [    0/   91]\n",
      "loss(769): 0.000128  [    0/   91]\n",
      "loss(770): 0.000118  [    0/   91]\n",
      "loss(771): 0.000121  [    0/   91]\n",
      "loss(772): 0.000153  [    0/   91]\n",
      "loss(773): 0.000112  [    0/   91]\n",
      "loss(774): 0.000123  [    0/   91]\n",
      "loss(775): 0.000100  [    0/   91]\n",
      "loss(776): 0.000079  [    0/   91]\n",
      "loss(777): 0.000087  [    0/   91]\n",
      "loss(778): 0.000097  [    0/   91]\n",
      "loss(779): 0.000107  [    0/   91]\n",
      "loss(780): 0.000094  [    0/   91]\n",
      "loss(781): 0.000096  [    0/   91]\n",
      "loss(782): 0.000125  [    0/   91]\n",
      "loss(783): 0.000113  [    0/   91]\n",
      "loss(784): 0.000119  [    0/   91]\n",
      "loss(785): 0.000125  [    0/   91]\n",
      "loss(786): 0.000102  [    0/   91]\n",
      "loss(787): 0.000091  [    0/   91]\n",
      "loss(788): 0.000098  [    0/   91]\n",
      "loss(789): 0.000106  [    0/   91]\n",
      "loss(790): 0.000104  [    0/   91]\n",
      "loss(791): 0.000092  [    0/   91]\n",
      "loss(792): 0.000104  [    0/   91]\n",
      "loss(793): 0.000104  [    0/   91]\n",
      "loss(794): 0.000094  [    0/   91]\n",
      "loss(795): 0.000124  [    0/   91]\n",
      "loss(796): 0.000128  [    0/   91]\n",
      "loss(797): 0.000115  [    0/   91]\n",
      "loss(798): 0.000109  [    0/   91]\n",
      "loss(799): 0.000157  [    0/   91]\n",
      "loss(800): 0.000142  [    0/   91]\n",
      "loss(801): 0.000108  [    0/   91]\n",
      "loss(802): 0.000114  [    0/   91]\n",
      "loss(803): 0.000118  [    0/   91]\n",
      "loss(804): 0.000141  [    0/   91]\n",
      "loss(805): 0.000121  [    0/   91]\n",
      "loss(806): 0.000105  [    0/   91]\n",
      "loss(807): 0.000096  [    0/   91]\n",
      "loss(808): 0.000130  [    0/   91]\n",
      "loss(809): 0.000107  [    0/   91]\n",
      "loss(810): 0.000107  [    0/   91]\n",
      "loss(811): 0.000107  [    0/   91]\n",
      "loss(812): 0.000117  [    0/   91]\n",
      "loss(813): 0.000093  [    0/   91]\n",
      "loss(814): 0.000072  [    0/   91]\n",
      "loss(815): 0.000122  [    0/   91]\n",
      "loss(816): 0.000118  [    0/   91]\n",
      "loss(817): 0.000088  [    0/   91]\n",
      "loss(818): 0.000078  [    0/   91]\n",
      "loss(819): 0.000092  [    0/   91]\n",
      "loss(820): 0.000077  [    0/   91]\n",
      "loss(821): 0.000104  [    0/   91]\n",
      "loss(822): 0.000117  [    0/   91]\n",
      "loss(823): 0.000119  [    0/   91]\n",
      "loss(824): 0.000105  [    0/   91]\n",
      "loss(825): 0.000106  [    0/   91]\n",
      "loss(826): 0.000081  [    0/   91]\n",
      "loss(827): 0.000141  [    0/   91]\n",
      "loss(828): 0.000112  [    0/   91]\n",
      "loss(829): 0.000086  [    0/   91]\n",
      "loss(830): 0.000124  [    0/   91]\n",
      "loss(831): 0.000140  [    0/   91]\n",
      "loss(832): 0.000093  [    0/   91]\n",
      "loss(833): 0.000116  [    0/   91]\n",
      "loss(834): 0.000124  [    0/   91]\n",
      "loss(835): 0.000115  [    0/   91]\n",
      "loss(836): 0.000107  [    0/   91]\n",
      "loss(837): 0.000112  [    0/   91]\n",
      "loss(838): 0.000093  [    0/   91]\n",
      "loss(839): 0.000094  [    0/   91]\n",
      "loss(840): 0.000102  [    0/   91]\n",
      "loss(841): 0.000106  [    0/   91]\n",
      "loss(842): 0.000107  [    0/   91]\n",
      "loss(843): 0.000120  [    0/   91]\n",
      "loss(844): 0.000115  [    0/   91]\n",
      "loss(845): 0.000072  [    0/   91]\n",
      "loss(846): 0.000091  [    0/   91]\n",
      "loss(847): 0.000119  [    0/   91]\n",
      "loss(848): 0.000125  [    0/   91]\n",
      "loss(849): 0.000128  [    0/   91]\n",
      "loss(850): 0.000122  [    0/   91]\n",
      "loss(851): 0.000107  [    0/   91]\n",
      "loss(852): 0.000116  [    0/   91]\n",
      "loss(853): 0.000134  [    0/   91]\n",
      "loss(854): 0.000122  [    0/   91]\n",
      "loss(855): 0.000107  [    0/   91]\n",
      "loss(856): 0.000115  [    0/   91]\n",
      "loss(857): 0.000105  [    0/   91]\n",
      "loss(858): 0.000083  [    0/   91]\n",
      "loss(859): 0.000097  [    0/   91]\n",
      "loss(860): 0.000110  [    0/   91]\n",
      "loss(861): 0.000121  [    0/   91]\n",
      "loss(862): 0.000122  [    0/   91]\n",
      "loss(863): 0.000116  [    0/   91]\n",
      "loss(864): 0.000111  [    0/   91]\n",
      "loss(865): 0.000105  [    0/   91]\n",
      "loss(866): 0.000111  [    0/   91]\n",
      "loss(867): 0.000117  [    0/   91]\n",
      "loss(868): 0.000101  [    0/   91]\n",
      "loss(869): 0.000112  [    0/   91]\n",
      "loss(870): 0.000093  [    0/   91]\n",
      "loss(871): 0.000104  [    0/   91]\n",
      "loss(872): 0.000113  [    0/   91]\n",
      "loss(873): 0.000105  [    0/   91]\n",
      "loss(874): 0.000087  [    0/   91]\n",
      "loss(875): 0.000113  [    0/   91]\n",
      "loss(876): 0.000112  [    0/   91]\n",
      "loss(877): 0.000093  [    0/   91]\n",
      "loss(878): 0.000107  [    0/   91]\n",
      "loss(879): 0.000112  [    0/   91]\n",
      "loss(880): 0.000112  [    0/   91]\n",
      "loss(881): 0.000098  [    0/   91]\n",
      "loss(882): 0.000100  [    0/   91]\n",
      "loss(883): 0.000112  [    0/   91]\n",
      "loss(884): 0.000138  [    0/   91]\n",
      "loss(885): 0.000103  [    0/   91]\n",
      "loss(886): 0.000110  [    0/   91]\n",
      "loss(887): 0.000115  [    0/   91]\n",
      "loss(888): 0.000135  [    0/   91]\n",
      "loss(889): 0.000117  [    0/   91]\n",
      "loss(890): 0.000085  [    0/   91]\n",
      "loss(891): 0.000113  [    0/   91]\n",
      "loss(892): 0.000119  [    0/   91]\n",
      "loss(893): 0.000068  [    0/   91]\n",
      "loss(894): 0.000097  [    0/   91]\n",
      "loss(895): 0.000118  [    0/   91]\n",
      "loss(896): 0.000109  [    0/   91]\n",
      "loss(897): 0.000090  [    0/   91]\n",
      "loss(898): 0.000105  [    0/   91]\n",
      "loss(899): 0.000115  [    0/   91]\n",
      "loss(900): 0.000106  [    0/   91]\n",
      "loss(901): 0.000097  [    0/   91]\n",
      "loss(902): 0.000116  [    0/   91]\n",
      "loss(903): 0.000111  [    0/   91]\n",
      "loss(904): 0.000117  [    0/   91]\n",
      "loss(905): 0.000085  [    0/   91]\n",
      "loss(906): 0.000101  [    0/   91]\n",
      "loss(907): 0.000081  [    0/   91]\n",
      "loss(908): 0.000123  [    0/   91]\n",
      "loss(909): 0.000121  [    0/   91]\n",
      "loss(910): 0.000079  [    0/   91]\n",
      "loss(911): 0.000112  [    0/   91]\n",
      "loss(912): 0.000122  [    0/   91]\n",
      "loss(913): 0.000118  [    0/   91]\n",
      "loss(914): 0.000098  [    0/   91]\n",
      "loss(915): 0.000106  [    0/   91]\n",
      "loss(916): 0.000100  [    0/   91]\n",
      "loss(917): 0.000086  [    0/   91]\n",
      "loss(918): 0.000104  [    0/   91]\n",
      "loss(919): 0.000086  [    0/   91]\n",
      "loss(920): 0.000101  [    0/   91]\n",
      "loss(921): 0.000113  [    0/   91]\n",
      "loss(922): 0.000133  [    0/   91]\n",
      "loss(923): 0.000079  [    0/   91]\n",
      "loss(924): 0.000081  [    0/   91]\n",
      "loss(925): 0.000121  [    0/   91]\n",
      "loss(926): 0.000112  [    0/   91]\n",
      "loss(927): 0.000113  [    0/   91]\n",
      "loss(928): 0.000118  [    0/   91]\n",
      "loss(929): 0.000090  [    0/   91]\n",
      "loss(930): 0.000110  [    0/   91]\n",
      "loss(931): 0.000141  [    0/   91]\n",
      "loss(932): 0.000107  [    0/   91]\n",
      "loss(933): 0.000109  [    0/   91]\n",
      "loss(934): 0.000109  [    0/   91]\n",
      "loss(935): 0.000115  [    0/   91]\n",
      "loss(936): 0.000114  [    0/   91]\n",
      "loss(937): 0.000115  [    0/   91]\n",
      "loss(938): 0.000130  [    0/   91]\n",
      "loss(939): 0.000125  [    0/   91]\n",
      "loss(940): 0.000078  [    0/   91]\n",
      "loss(941): 0.000133  [    0/   91]\n",
      "loss(942): 0.000100  [    0/   91]\n",
      "loss(943): 0.000129  [    0/   91]\n",
      "loss(944): 0.000108  [    0/   91]\n",
      "loss(945): 0.000105  [    0/   91]\n",
      "loss(946): 0.000113  [    0/   91]\n",
      "loss(947): 0.000103  [    0/   91]\n",
      "loss(948): 0.000110  [    0/   91]\n",
      "loss(949): 0.000071  [    0/   91]\n",
      "loss(950): 0.000111  [    0/   91]\n",
      "loss(951): 0.000099  [    0/   91]\n",
      "loss(952): 0.000109  [    0/   91]\n",
      "loss(953): 0.000095  [    0/   91]\n",
      "loss(954): 0.000105  [    0/   91]\n",
      "loss(955): 0.000100  [    0/   91]\n",
      "loss(956): 0.000110  [    0/   91]\n",
      "loss(957): 0.000102  [    0/   91]\n",
      "loss(958): 0.000105  [    0/   91]\n",
      "loss(959): 0.000079  [    0/   91]\n",
      "loss(960): 0.000080  [    0/   91]\n",
      "loss(961): 0.000112  [    0/   91]\n",
      "loss(962): 0.000106  [    0/   91]\n",
      "loss(963): 0.000114  [    0/   91]\n",
      "loss(964): 0.000096  [    0/   91]\n",
      "loss(965): 0.000077  [    0/   91]\n",
      "loss(966): 0.000090  [    0/   91]\n",
      "loss(967): 0.000096  [    0/   91]\n",
      "loss(968): 0.000090  [    0/   91]\n",
      "loss(969): 0.000087  [    0/   91]\n",
      "loss(970): 0.000084  [    0/   91]\n",
      "loss(971): 0.000107  [    0/   91]\n",
      "loss(972): 0.000086  [    0/   91]\n",
      "loss(973): 0.000130  [    0/   91]\n",
      "loss(974): 0.000126  [    0/   91]\n",
      "loss(975): 0.000079  [    0/   91]\n",
      "loss(976): 0.000113  [    0/   91]\n",
      "loss(977): 0.000139  [    0/   91]\n",
      "loss(978): 0.000131  [    0/   91]\n",
      "loss(979): 0.000135  [    0/   91]\n",
      "loss(980): 0.000103  [    0/   91]\n",
      "loss(981): 0.000113  [    0/   91]\n",
      "loss(982): 0.000076  [    0/   91]\n",
      "loss(983): 0.000130  [    0/   91]\n",
      "loss(984): 0.000135  [    0/   91]\n",
      "loss(985): 0.000110  [    0/   91]\n",
      "loss(986): 0.000111  [    0/   91]\n",
      "loss(987): 0.000085  [    0/   91]\n",
      "loss(988): 0.000116  [    0/   91]\n",
      "loss(989): 0.000101  [    0/   91]\n",
      "loss(990): 0.000077  [    0/   91]\n",
      "loss(991): 0.000134  [    0/   91]\n",
      "loss(992): 0.000158  [    0/   91]\n",
      "loss(993): 0.000123  [    0/   91]\n",
      "loss(994): 0.000087  [    0/   91]\n",
      "loss(995): 0.000120  [    0/   91]\n",
      "loss(996): 0.000113  [    0/   91]\n",
      "loss(997): 0.000130  [    0/   91]\n",
      "loss(998): 0.000113  [    0/   91]\n",
      "loss(999): 0.000120  [    0/   91]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .001\n",
    "epochs = 1000\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# print(list(model.parameters()))\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # break\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "Avg loss: 0.000091 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # print(X)\n",
    "            pred = model(X)\n",
    "            # print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error:\\nAvg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def test(model):\n",
    "    test_data = dataSetAll(2018,2100,numFeat,numOut)\n",
    "    norm = test_data.getNorm()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            Y = test_data[idx][1]*norm\n",
    "            feat = X[None,:]\n",
    "            pred = model(feat)[0]*norm\n",
    "            pred = pred[:,0] \n",
    "            Y = Y[:,0]  \n",
    "            plt.plot(Y)\n",
    "            plt.plot(pred)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def graph(model):\n",
    "    norm = test_data.getNorm()\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        res = []\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            y = test_data[idx][1]*norm\n",
    "            feat = X[None,:]\n",
    "\n",
    "            pred = model(feat)[0]*norm\n",
    "            future = 3\n",
    "\n",
    "            # predY.append(pred[numFeat-1::][future])\n",
    "            # actY.append(y[numFeat-1::][future]) \n",
    "            pred = pred[:,0] \n",
    "            y = y[:,0]  \n",
    "            # print(pred.size())\n",
    "            # print(float(pred[3]))\n",
    "            predY.append(pred[future])\n",
    "            actY.append(y[future])    \n",
    "            res.append(pred[future]-y[future])\n",
    "            \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        # plt.hist(res)\n",
    "        plt.show()\n",
    "        # print(np.std(res))\n",
    "\n",
    "graph(model)\n",
    "# test(model)\n",
    "test_loop(test_dataloader,model,loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2b87af6b5c43b3d2306d75b25b45e929fa9a7012d7025458fcc5adc9fcf8b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
