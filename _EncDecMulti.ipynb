{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CSV\n",
    "        self.df = pd.read_csv(\"data\\ILINet.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][[\"ILITOTAL\",\"% WEIGHTED ILI\",\"TOTAL PATIENTS\"]]\n",
    "\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        \n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        # print(self.data)\n",
    "        self.norm = np.linalg.norm(self.data, axis=0)\n",
    "        # print(self.norm)\n",
    "        self.data = self.data / self.norm\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # idx = 0\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]\n",
    "    \n",
    "    def getNorm(self):\n",
    "        return self.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 4\n",
    "batchSize = 64\n",
    "train_data = dataSetAll(1900,2022,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batchSize,drop_last=False,shuffle=True)\n",
    "\n",
    "test_data = dataSetAll(2022,2100,numFeat,numOut)\n",
    "test_dataloader = DataLoader(train_data, batch_size=batchSize,drop_last=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 3\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 32\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,numLayers,numOut,sequenceLength,future=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.numOut = numOut\n",
    "        self.future = future\n",
    "        self.inputSize = inputSize\n",
    "        # print(batchSize,sequenceLength,inputSize)\n",
    "        # self.LSTM = nn.LSTM(inputSize,hiddenSize,numLayers,batch_first=True)\n",
    "        self.rnn1 = nn.RNNCell(inputSize,hiddenSize)\n",
    "        self.rnn2 = nn.RNNCell(inputSize,hiddenSize)\n",
    "        self.rnn3 = nn.RNNCell(inputSize,hiddenSize)\n",
    "        self.rnn4 = nn.RNNCell(inputSize,hiddenSize)\n",
    "        # self.rnn2 = nn.RNNCell(1,hiddenSize,nonlinearity='tanh')\n",
    "        self.fc1 = nn.Linear(hiddenSize,inputSize)\n",
    "        self.fc2 = nn.Linear(hiddenSize,inputSize)\n",
    "        self.fc3 = nn.Linear(hiddenSize,inputSize)\n",
    "        self.fc4 = nn.Linear(hiddenSize,inputSize)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        nSamples = x.size(0)\n",
    "        outputs = torch.zeros([nSamples,self.numOut,self.inputSize])\n",
    "        h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        h_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "\n",
    "        for input in x.split(1,dim=1):\n",
    "            h_1 = self.rnn1(input[:,0,:], h_1)\n",
    "            out = self.fc1(h_1)\n",
    "        outputs[:,0] = out\n",
    "\n",
    "        h_1 = self.rnn2(out, h_1)\n",
    "        out = self.fc2(h_1)\n",
    "        outputs[:,1] = out\n",
    "\n",
    "        h_1 = self.rnn3(out, h_1)\n",
    "        out = self.fc3(h_1)\n",
    "        outputs[:,2] = out\n",
    "\n",
    "        h_1 = self.rnn4(out, h_1)\n",
    "        out = self.fc4(h_1)\n",
    "        outputs[:,3] = out\n",
    "\n",
    "        # outputs = torch.as_tensor(outputs)\n",
    "        return outputs\n",
    "\n",
    "model = RNN(inputSize,hiddenSize,numLayers,numOut,sequenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(X.size())\n",
    "        # X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        # break\n",
    "        # print(pred.size())\n",
    "        # print(y.size())\n",
    "        # print(\"pred\",pred.size())\n",
    "        # print(\"Y\",y.size())\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 0.016013  [    0/   91]\n",
      "loss(1): 0.005820  [    0/   91]\n",
      "loss(2): 0.002191  [    0/   91]\n",
      "loss(3): 0.001611  [    0/   91]\n",
      "loss(4): 0.001806  [    0/   91]\n",
      "loss(5): 0.001463  [    0/   91]\n",
      "loss(6): 0.001181  [    0/   91]\n",
      "loss(7): 0.000945  [    0/   91]\n",
      "loss(8): 0.000847  [    0/   91]\n",
      "loss(9): 0.001110  [    0/   91]\n",
      "loss(10): 0.000831  [    0/   91]\n",
      "loss(11): 0.000855  [    0/   91]\n",
      "loss(12): 0.000771  [    0/   91]\n",
      "loss(13): 0.000673  [    0/   91]\n",
      "loss(14): 0.000694  [    0/   91]\n",
      "loss(15): 0.000816  [    0/   91]\n",
      "loss(16): 0.000707  [    0/   91]\n",
      "loss(17): 0.000772  [    0/   91]\n",
      "loss(18): 0.000774  [    0/   91]\n",
      "loss(19): 0.000505  [    0/   91]\n",
      "loss(20): 0.000557  [    0/   91]\n",
      "loss(21): 0.000677  [    0/   91]\n",
      "loss(22): 0.000776  [    0/   91]\n",
      "loss(23): 0.000687  [    0/   91]\n",
      "loss(24): 0.000616  [    0/   91]\n",
      "loss(25): 0.000704  [    0/   91]\n",
      "loss(26): 0.000631  [    0/   91]\n",
      "loss(27): 0.000567  [    0/   91]\n",
      "loss(28): 0.000646  [    0/   91]\n",
      "loss(29): 0.000581  [    0/   91]\n",
      "loss(30): 0.000667  [    0/   91]\n",
      "loss(31): 0.000502  [    0/   91]\n",
      "loss(32): 0.000508  [    0/   91]\n",
      "loss(33): 0.000594  [    0/   91]\n",
      "loss(34): 0.000525  [    0/   91]\n",
      "loss(35): 0.000555  [    0/   91]\n",
      "loss(36): 0.000563  [    0/   91]\n",
      "loss(37): 0.000574  [    0/   91]\n",
      "loss(38): 0.000490  [    0/   91]\n",
      "loss(39): 0.000518  [    0/   91]\n",
      "loss(40): 0.000525  [    0/   91]\n",
      "loss(41): 0.000510  [    0/   91]\n",
      "loss(42): 0.000436  [    0/   91]\n",
      "loss(43): 0.000406  [    0/   91]\n",
      "loss(44): 0.000425  [    0/   91]\n",
      "loss(45): 0.000476  [    0/   91]\n",
      "loss(46): 0.000397  [    0/   91]\n",
      "loss(47): 0.000407  [    0/   91]\n",
      "loss(48): 0.000413  [    0/   91]\n",
      "loss(49): 0.000334  [    0/   91]\n",
      "loss(50): 0.000423  [    0/   91]\n",
      "loss(51): 0.000376  [    0/   91]\n",
      "loss(52): 0.000356  [    0/   91]\n",
      "loss(53): 0.000399  [    0/   91]\n",
      "loss(54): 0.000389  [    0/   91]\n",
      "loss(55): 0.000391  [    0/   91]\n",
      "loss(56): 0.000327  [    0/   91]\n",
      "loss(57): 0.000369  [    0/   91]\n",
      "loss(58): 0.000295  [    0/   91]\n",
      "loss(59): 0.000363  [    0/   91]\n",
      "loss(60): 0.000391  [    0/   91]\n",
      "loss(61): 0.000318  [    0/   91]\n",
      "loss(62): 0.000332  [    0/   91]\n",
      "loss(63): 0.000339  [    0/   91]\n",
      "loss(64): 0.000383  [    0/   91]\n",
      "loss(65): 0.000342  [    0/   91]\n",
      "loss(66): 0.000326  [    0/   91]\n",
      "loss(67): 0.000256  [    0/   91]\n",
      "loss(68): 0.000342  [    0/   91]\n",
      "loss(69): 0.000284  [    0/   91]\n",
      "loss(70): 0.000353  [    0/   91]\n",
      "loss(71): 0.000329  [    0/   91]\n",
      "loss(72): 0.000312  [    0/   91]\n",
      "loss(73): 0.000312  [    0/   91]\n",
      "loss(74): 0.000301  [    0/   91]\n",
      "loss(75): 0.000279  [    0/   91]\n",
      "loss(76): 0.000292  [    0/   91]\n",
      "loss(77): 0.000248  [    0/   91]\n",
      "loss(78): 0.000250  [    0/   91]\n",
      "loss(79): 0.000216  [    0/   91]\n",
      "loss(80): 0.000234  [    0/   91]\n",
      "loss(81): 0.000229  [    0/   91]\n",
      "loss(82): 0.000237  [    0/   91]\n",
      "loss(83): 0.000251  [    0/   91]\n",
      "loss(84): 0.000230  [    0/   91]\n",
      "loss(85): 0.000205  [    0/   91]\n",
      "loss(86): 0.000193  [    0/   91]\n",
      "loss(87): 0.000188  [    0/   91]\n",
      "loss(88): 0.000212  [    0/   91]\n",
      "loss(89): 0.000239  [    0/   91]\n",
      "loss(90): 0.000193  [    0/   91]\n",
      "loss(91): 0.000185  [    0/   91]\n",
      "loss(92): 0.000153  [    0/   91]\n",
      "loss(93): 0.000257  [    0/   91]\n",
      "loss(94): 0.000185  [    0/   91]\n",
      "loss(95): 0.000229  [    0/   91]\n",
      "loss(96): 0.000240  [    0/   91]\n",
      "loss(97): 0.000205  [    0/   91]\n",
      "loss(98): 0.000183  [    0/   91]\n",
      "loss(99): 0.000200  [    0/   91]\n",
      "loss(100): 0.000183  [    0/   91]\n",
      "loss(101): 0.000165  [    0/   91]\n",
      "loss(102): 0.000159  [    0/   91]\n",
      "loss(103): 0.000169  [    0/   91]\n",
      "loss(104): 0.000199  [    0/   91]\n",
      "loss(105): 0.000185  [    0/   91]\n",
      "loss(106): 0.000179  [    0/   91]\n",
      "loss(107): 0.000187  [    0/   91]\n",
      "loss(108): 0.000186  [    0/   91]\n",
      "loss(109): 0.000195  [    0/   91]\n",
      "loss(110): 0.000190  [    0/   91]\n",
      "loss(111): 0.000221  [    0/   91]\n",
      "loss(112): 0.000197  [    0/   91]\n",
      "loss(113): 0.000264  [    0/   91]\n",
      "loss(114): 0.000182  [    0/   91]\n",
      "loss(115): 0.000201  [    0/   91]\n",
      "loss(116): 0.000237  [    0/   91]\n",
      "loss(117): 0.000159  [    0/   91]\n",
      "loss(118): 0.000214  [    0/   91]\n",
      "loss(119): 0.000184  [    0/   91]\n",
      "loss(120): 0.000190  [    0/   91]\n",
      "loss(121): 0.000153  [    0/   91]\n",
      "loss(122): 0.000191  [    0/   91]\n",
      "loss(123): 0.000148  [    0/   91]\n",
      "loss(124): 0.000174  [    0/   91]\n",
      "loss(125): 0.000160  [    0/   91]\n",
      "loss(126): 0.000174  [    0/   91]\n",
      "loss(127): 0.000200  [    0/   91]\n",
      "loss(128): 0.000138  [    0/   91]\n",
      "loss(129): 0.000154  [    0/   91]\n",
      "loss(130): 0.000135  [    0/   91]\n",
      "loss(131): 0.000174  [    0/   91]\n",
      "loss(132): 0.000163  [    0/   91]\n",
      "loss(133): 0.000159  [    0/   91]\n",
      "loss(134): 0.000154  [    0/   91]\n",
      "loss(135): 0.000161  [    0/   91]\n",
      "loss(136): 0.000158  [    0/   91]\n",
      "loss(137): 0.000190  [    0/   91]\n",
      "loss(138): 0.000170  [    0/   91]\n",
      "loss(139): 0.000174  [    0/   91]\n",
      "loss(140): 0.000138  [    0/   91]\n",
      "loss(141): 0.000147  [    0/   91]\n",
      "loss(142): 0.000185  [    0/   91]\n",
      "loss(143): 0.000147  [    0/   91]\n",
      "loss(144): 0.000141  [    0/   91]\n",
      "loss(145): 0.000158  [    0/   91]\n",
      "loss(146): 0.000153  [    0/   91]\n",
      "loss(147): 0.000160  [    0/   91]\n",
      "loss(148): 0.000126  [    0/   91]\n",
      "loss(149): 0.000184  [    0/   91]\n",
      "loss(150): 0.000135  [    0/   91]\n",
      "loss(151): 0.000138  [    0/   91]\n",
      "loss(152): 0.000161  [    0/   91]\n",
      "loss(153): 0.000139  [    0/   91]\n",
      "loss(154): 0.000139  [    0/   91]\n",
      "loss(155): 0.000129  [    0/   91]\n",
      "loss(156): 0.000094  [    0/   91]\n",
      "loss(157): 0.000172  [    0/   91]\n",
      "loss(158): 0.000144  [    0/   91]\n",
      "loss(159): 0.000163  [    0/   91]\n",
      "loss(160): 0.000116  [    0/   91]\n",
      "loss(161): 0.000181  [    0/   91]\n",
      "loss(162): 0.000118  [    0/   91]\n",
      "loss(163): 0.000102  [    0/   91]\n",
      "loss(164): 0.000124  [    0/   91]\n",
      "loss(165): 0.000125  [    0/   91]\n",
      "loss(166): 0.000170  [    0/   91]\n",
      "loss(167): 0.000120  [    0/   91]\n",
      "loss(168): 0.000132  [    0/   91]\n",
      "loss(169): 0.000157  [    0/   91]\n",
      "loss(170): 0.000132  [    0/   91]\n",
      "loss(171): 0.000150  [    0/   91]\n",
      "loss(172): 0.000134  [    0/   91]\n",
      "loss(173): 0.000134  [    0/   91]\n",
      "loss(174): 0.000161  [    0/   91]\n",
      "loss(175): 0.000154  [    0/   91]\n",
      "loss(176): 0.000156  [    0/   91]\n",
      "loss(177): 0.000147  [    0/   91]\n",
      "loss(178): 0.000115  [    0/   91]\n",
      "loss(179): 0.000158  [    0/   91]\n",
      "loss(180): 0.000161  [    0/   91]\n",
      "loss(181): 0.000150  [    0/   91]\n",
      "loss(182): 0.000135  [    0/   91]\n",
      "loss(183): 0.000149  [    0/   91]\n",
      "loss(184): 0.000178  [    0/   91]\n",
      "loss(185): 0.000130  [    0/   91]\n",
      "loss(186): 0.000160  [    0/   91]\n",
      "loss(187): 0.000127  [    0/   91]\n",
      "loss(188): 0.000147  [    0/   91]\n",
      "loss(189): 0.000110  [    0/   91]\n",
      "loss(190): 0.000164  [    0/   91]\n",
      "loss(191): 0.000159  [    0/   91]\n",
      "loss(192): 0.000121  [    0/   91]\n",
      "loss(193): 0.000116  [    0/   91]\n",
      "loss(194): 0.000126  [    0/   91]\n",
      "loss(195): 0.000139  [    0/   91]\n",
      "loss(196): 0.000140  [    0/   91]\n",
      "loss(197): 0.000102  [    0/   91]\n",
      "loss(198): 0.000115  [    0/   91]\n",
      "loss(199): 0.000129  [    0/   91]\n",
      "loss(200): 0.000133  [    0/   91]\n",
      "loss(201): 0.000145  [    0/   91]\n",
      "loss(202): 0.000143  [    0/   91]\n",
      "loss(203): 0.000125  [    0/   91]\n",
      "loss(204): 0.000130  [    0/   91]\n",
      "loss(205): 0.000132  [    0/   91]\n",
      "loss(206): 0.000100  [    0/   91]\n",
      "loss(207): 0.000121  [    0/   91]\n",
      "loss(208): 0.000129  [    0/   91]\n",
      "loss(209): 0.000128  [    0/   91]\n",
      "loss(210): 0.000109  [    0/   91]\n",
      "loss(211): 0.000136  [    0/   91]\n",
      "loss(212): 0.000120  [    0/   91]\n",
      "loss(213): 0.000126  [    0/   91]\n",
      "loss(214): 0.000122  [    0/   91]\n",
      "loss(215): 0.000135  [    0/   91]\n",
      "loss(216): 0.000138  [    0/   91]\n",
      "loss(217): 0.000125  [    0/   91]\n",
      "loss(218): 0.000130  [    0/   91]\n",
      "loss(219): 0.000091  [    0/   91]\n",
      "loss(220): 0.000115  [    0/   91]\n",
      "loss(221): 0.000133  [    0/   91]\n",
      "loss(222): 0.000135  [    0/   91]\n",
      "loss(223): 0.000137  [    0/   91]\n",
      "loss(224): 0.000125  [    0/   91]\n",
      "loss(225): 0.000095  [    0/   91]\n",
      "loss(226): 0.000094  [    0/   91]\n",
      "loss(227): 0.000140  [    0/   91]\n",
      "loss(228): 0.000119  [    0/   91]\n",
      "loss(229): 0.000123  [    0/   91]\n",
      "loss(230): 0.000106  [    0/   91]\n",
      "loss(231): 0.000122  [    0/   91]\n",
      "loss(232): 0.000084  [    0/   91]\n",
      "loss(233): 0.000125  [    0/   91]\n",
      "loss(234): 0.000139  [    0/   91]\n",
      "loss(235): 0.000119  [    0/   91]\n",
      "loss(236): 0.000090  [    0/   91]\n",
      "loss(237): 0.000105  [    0/   91]\n",
      "loss(238): 0.000091  [    0/   91]\n",
      "loss(239): 0.000109  [    0/   91]\n",
      "loss(240): 0.000128  [    0/   91]\n",
      "loss(241): 0.000098  [    0/   91]\n",
      "loss(242): 0.000117  [    0/   91]\n",
      "loss(243): 0.000195  [    0/   91]\n",
      "loss(244): 0.000147  [    0/   91]\n",
      "loss(245): 0.000121  [    0/   91]\n",
      "loss(246): 0.000134  [    0/   91]\n",
      "loss(247): 0.000130  [    0/   91]\n",
      "loss(248): 0.000115  [    0/   91]\n",
      "loss(249): 0.000116  [    0/   91]\n",
      "loss(250): 0.000105  [    0/   91]\n",
      "loss(251): 0.000114  [    0/   91]\n",
      "loss(252): 0.000117  [    0/   91]\n",
      "loss(253): 0.000111  [    0/   91]\n",
      "loss(254): 0.000136  [    0/   91]\n",
      "loss(255): 0.000128  [    0/   91]\n",
      "loss(256): 0.000092  [    0/   91]\n",
      "loss(257): 0.000114  [    0/   91]\n",
      "loss(258): 0.000099  [    0/   91]\n",
      "loss(259): 0.000105  [    0/   91]\n",
      "loss(260): 0.000135  [    0/   91]\n",
      "loss(261): 0.000069  [    0/   91]\n",
      "loss(262): 0.000139  [    0/   91]\n",
      "loss(263): 0.000118  [    0/   91]\n",
      "loss(264): 0.000183  [    0/   91]\n",
      "loss(265): 0.000163  [    0/   91]\n",
      "loss(266): 0.000107  [    0/   91]\n",
      "loss(267): 0.000124  [    0/   91]\n",
      "loss(268): 0.000097  [    0/   91]\n",
      "loss(269): 0.000123  [    0/   91]\n",
      "loss(270): 0.000121  [    0/   91]\n",
      "loss(271): 0.000090  [    0/   91]\n",
      "loss(272): 0.000139  [    0/   91]\n",
      "loss(273): 0.000121  [    0/   91]\n",
      "loss(274): 0.000124  [    0/   91]\n",
      "loss(275): 0.000116  [    0/   91]\n",
      "loss(276): 0.000102  [    0/   91]\n",
      "loss(277): 0.000099  [    0/   91]\n",
      "loss(278): 0.000094  [    0/   91]\n",
      "loss(279): 0.000129  [    0/   91]\n",
      "loss(280): 0.000149  [    0/   91]\n",
      "loss(281): 0.000194  [    0/   91]\n",
      "loss(282): 0.000107  [    0/   91]\n",
      "loss(283): 0.000168  [    0/   91]\n",
      "loss(284): 0.000101  [    0/   91]\n",
      "loss(285): 0.000101  [    0/   91]\n",
      "loss(286): 0.000104  [    0/   91]\n",
      "loss(287): 0.000189  [    0/   91]\n",
      "loss(288): 0.000178  [    0/   91]\n",
      "loss(289): 0.000130  [    0/   91]\n",
      "loss(290): 0.000112  [    0/   91]\n",
      "loss(291): 0.000075  [    0/   91]\n",
      "loss(292): 0.000114  [    0/   91]\n",
      "loss(293): 0.000107  [    0/   91]\n",
      "loss(294): 0.000085  [    0/   91]\n",
      "loss(295): 0.000122  [    0/   91]\n",
      "loss(296): 0.000094  [    0/   91]\n",
      "loss(297): 0.000116  [    0/   91]\n",
      "loss(298): 0.000104  [    0/   91]\n",
      "loss(299): 0.000087  [    0/   91]\n",
      "loss(300): 0.000102  [    0/   91]\n",
      "loss(301): 0.000107  [    0/   91]\n",
      "loss(302): 0.000117  [    0/   91]\n",
      "loss(303): 0.000115  [    0/   91]\n",
      "loss(304): 0.000115  [    0/   91]\n",
      "loss(305): 0.000114  [    0/   91]\n",
      "loss(306): 0.000116  [    0/   91]\n",
      "loss(307): 0.000118  [    0/   91]\n",
      "loss(308): 0.000119  [    0/   91]\n",
      "loss(309): 0.000128  [    0/   91]\n",
      "loss(310): 0.000099  [    0/   91]\n",
      "loss(311): 0.000076  [    0/   91]\n",
      "loss(312): 0.000119  [    0/   91]\n",
      "loss(313): 0.000103  [    0/   91]\n",
      "loss(314): 0.000088  [    0/   91]\n",
      "loss(315): 0.000100  [    0/   91]\n",
      "loss(316): 0.000111  [    0/   91]\n",
      "loss(317): 0.000099  [    0/   91]\n",
      "loss(318): 0.000101  [    0/   91]\n",
      "loss(319): 0.000114  [    0/   91]\n",
      "loss(320): 0.000116  [    0/   91]\n",
      "loss(321): 0.000111  [    0/   91]\n",
      "loss(322): 0.000088  [    0/   91]\n",
      "loss(323): 0.000116  [    0/   91]\n",
      "loss(324): 0.000098  [    0/   91]\n",
      "loss(325): 0.000114  [    0/   91]\n",
      "loss(326): 0.000121  [    0/   91]\n",
      "loss(327): 0.000100  [    0/   91]\n",
      "loss(328): 0.000111  [    0/   91]\n",
      "loss(329): 0.000116  [    0/   91]\n",
      "loss(330): 0.000073  [    0/   91]\n",
      "loss(331): 0.000108  [    0/   91]\n",
      "loss(332): 0.000125  [    0/   91]\n",
      "loss(333): 0.000121  [    0/   91]\n",
      "loss(334): 0.000104  [    0/   91]\n",
      "loss(335): 0.000107  [    0/   91]\n",
      "loss(336): 0.000109  [    0/   91]\n",
      "loss(337): 0.000074  [    0/   91]\n",
      "loss(338): 0.000095  [    0/   91]\n",
      "loss(339): 0.000098  [    0/   91]\n",
      "loss(340): 0.000092  [    0/   91]\n",
      "loss(341): 0.000103  [    0/   91]\n",
      "loss(342): 0.000125  [    0/   91]\n",
      "loss(343): 0.000124  [    0/   91]\n",
      "loss(344): 0.000062  [    0/   91]\n",
      "loss(345): 0.000115  [    0/   91]\n",
      "loss(346): 0.000084  [    0/   91]\n",
      "loss(347): 0.000106  [    0/   91]\n",
      "loss(348): 0.000117  [    0/   91]\n",
      "loss(349): 0.000112  [    0/   91]\n",
      "loss(350): 0.000145  [    0/   91]\n",
      "loss(351): 0.000114  [    0/   91]\n",
      "loss(352): 0.000109  [    0/   91]\n",
      "loss(353): 0.000123  [    0/   91]\n",
      "loss(354): 0.000140  [    0/   91]\n",
      "loss(355): 0.000125  [    0/   91]\n",
      "loss(356): 0.000115  [    0/   91]\n",
      "loss(357): 0.000102  [    0/   91]\n",
      "loss(358): 0.000106  [    0/   91]\n",
      "loss(359): 0.000079  [    0/   91]\n",
      "loss(360): 0.000088  [    0/   91]\n",
      "loss(361): 0.000110  [    0/   91]\n",
      "loss(362): 0.000057  [    0/   91]\n",
      "loss(363): 0.000094  [    0/   91]\n",
      "loss(364): 0.000092  [    0/   91]\n",
      "loss(365): 0.000115  [    0/   91]\n",
      "loss(366): 0.000094  [    0/   91]\n",
      "loss(367): 0.000098  [    0/   91]\n",
      "loss(368): 0.000113  [    0/   91]\n",
      "loss(369): 0.000095  [    0/   91]\n",
      "loss(370): 0.000126  [    0/   91]\n",
      "loss(371): 0.000079  [    0/   91]\n",
      "loss(372): 0.000109  [    0/   91]\n",
      "loss(373): 0.000088  [    0/   91]\n",
      "loss(374): 0.000110  [    0/   91]\n",
      "loss(375): 0.000100  [    0/   91]\n",
      "loss(376): 0.000089  [    0/   91]\n",
      "loss(377): 0.000087  [    0/   91]\n",
      "loss(378): 0.000111  [    0/   91]\n",
      "loss(379): 0.000095  [    0/   91]\n",
      "loss(380): 0.000103  [    0/   91]\n",
      "loss(381): 0.000111  [    0/   91]\n",
      "loss(382): 0.000078  [    0/   91]\n",
      "loss(383): 0.000100  [    0/   91]\n",
      "loss(384): 0.000088  [    0/   91]\n",
      "loss(385): 0.000084  [    0/   91]\n",
      "loss(386): 0.000111  [    0/   91]\n",
      "loss(387): 0.000084  [    0/   91]\n",
      "loss(388): 0.000091  [    0/   91]\n",
      "loss(389): 0.000102  [    0/   91]\n",
      "loss(390): 0.000105  [    0/   91]\n",
      "loss(391): 0.000100  [    0/   91]\n",
      "loss(392): 0.000099  [    0/   91]\n",
      "loss(393): 0.000063  [    0/   91]\n",
      "loss(394): 0.000095  [    0/   91]\n",
      "loss(395): 0.000082  [    0/   91]\n",
      "loss(396): 0.000081  [    0/   91]\n",
      "loss(397): 0.000105  [    0/   91]\n",
      "loss(398): 0.000097  [    0/   91]\n",
      "loss(399): 0.000109  [    0/   91]\n",
      "loss(400): 0.000093  [    0/   91]\n",
      "loss(401): 0.000078  [    0/   91]\n",
      "loss(402): 0.000076  [    0/   91]\n",
      "loss(403): 0.000085  [    0/   91]\n",
      "loss(404): 0.000116  [    0/   91]\n",
      "loss(405): 0.000096  [    0/   91]\n",
      "loss(406): 0.000092  [    0/   91]\n",
      "loss(407): 0.000093  [    0/   91]\n",
      "loss(408): 0.000112  [    0/   91]\n",
      "loss(409): 0.000083  [    0/   91]\n",
      "loss(410): 0.000089  [    0/   91]\n",
      "loss(411): 0.000101  [    0/   91]\n",
      "loss(412): 0.000099  [    0/   91]\n",
      "loss(413): 0.000068  [    0/   91]\n",
      "loss(414): 0.000074  [    0/   91]\n",
      "loss(415): 0.000103  [    0/   91]\n",
      "loss(416): 0.000128  [    0/   91]\n",
      "loss(417): 0.000152  [    0/   91]\n",
      "loss(418): 0.000097  [    0/   91]\n",
      "loss(419): 0.000126  [    0/   91]\n",
      "loss(420): 0.000109  [    0/   91]\n",
      "loss(421): 0.000080  [    0/   91]\n",
      "loss(422): 0.000096  [    0/   91]\n",
      "loss(423): 0.000093  [    0/   91]\n",
      "loss(424): 0.000103  [    0/   91]\n",
      "loss(425): 0.000090  [    0/   91]\n",
      "loss(426): 0.000082  [    0/   91]\n",
      "loss(427): 0.000097  [    0/   91]\n",
      "loss(428): 0.000101  [    0/   91]\n",
      "loss(429): 0.000113  [    0/   91]\n",
      "loss(430): 0.000085  [    0/   91]\n",
      "loss(431): 0.000116  [    0/   91]\n",
      "loss(432): 0.000086  [    0/   91]\n",
      "loss(433): 0.000073  [    0/   91]\n",
      "loss(434): 0.000104  [    0/   91]\n",
      "loss(435): 0.000116  [    0/   91]\n",
      "loss(436): 0.000096  [    0/   91]\n",
      "loss(437): 0.000099  [    0/   91]\n",
      "loss(438): 0.000096  [    0/   91]\n",
      "loss(439): 0.000081  [    0/   91]\n",
      "loss(440): 0.000098  [    0/   91]\n",
      "loss(441): 0.000084  [    0/   91]\n",
      "loss(442): 0.000116  [    0/   91]\n",
      "loss(443): 0.000119  [    0/   91]\n",
      "loss(444): 0.000109  [    0/   91]\n",
      "loss(445): 0.000090  [    0/   91]\n",
      "loss(446): 0.000075  [    0/   91]\n",
      "loss(447): 0.000075  [    0/   91]\n",
      "loss(448): 0.000076  [    0/   91]\n",
      "loss(449): 0.000106  [    0/   91]\n",
      "loss(450): 0.000083  [    0/   91]\n",
      "loss(451): 0.000076  [    0/   91]\n",
      "loss(452): 0.000106  [    0/   91]\n",
      "loss(453): 0.000086  [    0/   91]\n",
      "loss(454): 0.000104  [    0/   91]\n",
      "loss(455): 0.000075  [    0/   91]\n",
      "loss(456): 0.000100  [    0/   91]\n",
      "loss(457): 0.000104  [    0/   91]\n",
      "loss(458): 0.000091  [    0/   91]\n",
      "loss(459): 0.000088  [    0/   91]\n",
      "loss(460): 0.000087  [    0/   91]\n",
      "loss(461): 0.000061  [    0/   91]\n",
      "loss(462): 0.000066  [    0/   91]\n",
      "loss(463): 0.000086  [    0/   91]\n",
      "loss(464): 0.000095  [    0/   91]\n",
      "loss(465): 0.000086  [    0/   91]\n",
      "loss(466): 0.000091  [    0/   91]\n",
      "loss(467): 0.000094  [    0/   91]\n",
      "loss(468): 0.000097  [    0/   91]\n",
      "loss(469): 0.000105  [    0/   91]\n",
      "loss(470): 0.000105  [    0/   91]\n",
      "loss(471): 0.000074  [    0/   91]\n",
      "loss(472): 0.000090  [    0/   91]\n",
      "loss(473): 0.000085  [    0/   91]\n",
      "loss(474): 0.000103  [    0/   91]\n",
      "loss(475): 0.000089  [    0/   91]\n",
      "loss(476): 0.000072  [    0/   91]\n",
      "loss(477): 0.000111  [    0/   91]\n",
      "loss(478): 0.000117  [    0/   91]\n",
      "loss(479): 0.000118  [    0/   91]\n",
      "loss(480): 0.000109  [    0/   91]\n",
      "loss(481): 0.000102  [    0/   91]\n",
      "loss(482): 0.000080  [    0/   91]\n",
      "loss(483): 0.000087  [    0/   91]\n",
      "loss(484): 0.000079  [    0/   91]\n",
      "loss(485): 0.000088  [    0/   91]\n",
      "loss(486): 0.000108  [    0/   91]\n",
      "loss(487): 0.000105  [    0/   91]\n",
      "loss(488): 0.000100  [    0/   91]\n",
      "loss(489): 0.000127  [    0/   91]\n",
      "loss(490): 0.000108  [    0/   91]\n",
      "loss(491): 0.000105  [    0/   91]\n",
      "loss(492): 0.000091  [    0/   91]\n",
      "loss(493): 0.000092  [    0/   91]\n",
      "loss(494): 0.000126  [    0/   91]\n",
      "loss(495): 0.000078  [    0/   91]\n",
      "loss(496): 0.000098  [    0/   91]\n",
      "loss(497): 0.000102  [    0/   91]\n",
      "loss(498): 0.000100  [    0/   91]\n",
      "loss(499): 0.000102  [    0/   91]\n",
      "loss(500): 0.000092  [    0/   91]\n",
      "loss(501): 0.000107  [    0/   91]\n",
      "loss(502): 0.000096  [    0/   91]\n",
      "loss(503): 0.000097  [    0/   91]\n",
      "loss(504): 0.000069  [    0/   91]\n",
      "loss(505): 0.000065  [    0/   91]\n",
      "loss(506): 0.000072  [    0/   91]\n",
      "loss(507): 0.000085  [    0/   91]\n",
      "loss(508): 0.000088  [    0/   91]\n",
      "loss(509): 0.000118  [    0/   91]\n",
      "loss(510): 0.000098  [    0/   91]\n",
      "loss(511): 0.000088  [    0/   91]\n",
      "loss(512): 0.000111  [    0/   91]\n",
      "loss(513): 0.000088  [    0/   91]\n",
      "loss(514): 0.000129  [    0/   91]\n",
      "loss(515): 0.000102  [    0/   91]\n",
      "loss(516): 0.000109  [    0/   91]\n",
      "loss(517): 0.000105  [    0/   91]\n",
      "loss(518): 0.000092  [    0/   91]\n",
      "loss(519): 0.000098  [    0/   91]\n",
      "loss(520): 0.000068  [    0/   91]\n",
      "loss(521): 0.000087  [    0/   91]\n",
      "loss(522): 0.000095  [    0/   91]\n",
      "loss(523): 0.000092  [    0/   91]\n",
      "loss(524): 0.000094  [    0/   91]\n",
      "loss(525): 0.000073  [    0/   91]\n",
      "loss(526): 0.000104  [    0/   91]\n",
      "loss(527): 0.000082  [    0/   91]\n",
      "loss(528): 0.000091  [    0/   91]\n",
      "loss(529): 0.000090  [    0/   91]\n",
      "loss(530): 0.000076  [    0/   91]\n",
      "loss(531): 0.000076  [    0/   91]\n",
      "loss(532): 0.000101  [    0/   91]\n",
      "loss(533): 0.000086  [    0/   91]\n",
      "loss(534): 0.000068  [    0/   91]\n",
      "loss(535): 0.000083  [    0/   91]\n",
      "loss(536): 0.000076  [    0/   91]\n",
      "loss(537): 0.000106  [    0/   91]\n",
      "loss(538): 0.000112  [    0/   91]\n",
      "loss(539): 0.000080  [    0/   91]\n",
      "loss(540): 0.000085  [    0/   91]\n",
      "loss(541): 0.000096  [    0/   91]\n",
      "loss(542): 0.000092  [    0/   91]\n",
      "loss(543): 0.000125  [    0/   91]\n",
      "loss(544): 0.000105  [    0/   91]\n",
      "loss(545): 0.000092  [    0/   91]\n",
      "loss(546): 0.000090  [    0/   91]\n",
      "loss(547): 0.000089  [    0/   91]\n",
      "loss(548): 0.000066  [    0/   91]\n",
      "loss(549): 0.000094  [    0/   91]\n",
      "loss(550): 0.000111  [    0/   91]\n",
      "loss(551): 0.000062  [    0/   91]\n",
      "loss(552): 0.000090  [    0/   91]\n",
      "loss(553): 0.000100  [    0/   91]\n",
      "loss(554): 0.000061  [    0/   91]\n",
      "loss(555): 0.000096  [    0/   91]\n",
      "loss(556): 0.000073  [    0/   91]\n",
      "loss(557): 0.000095  [    0/   91]\n",
      "loss(558): 0.000096  [    0/   91]\n",
      "loss(559): 0.000087  [    0/   91]\n",
      "loss(560): 0.000092  [    0/   91]\n",
      "loss(561): 0.000095  [    0/   91]\n",
      "loss(562): 0.000094  [    0/   91]\n",
      "loss(563): 0.000073  [    0/   91]\n",
      "loss(564): 0.000096  [    0/   91]\n",
      "loss(565): 0.000100  [    0/   91]\n",
      "loss(566): 0.000088  [    0/   91]\n",
      "loss(567): 0.000096  [    0/   91]\n",
      "loss(568): 0.000087  [    0/   91]\n",
      "loss(569): 0.000090  [    0/   91]\n",
      "loss(570): 0.000086  [    0/   91]\n",
      "loss(571): 0.000067  [    0/   91]\n",
      "loss(572): 0.000095  [    0/   91]\n",
      "loss(573): 0.000091  [    0/   91]\n",
      "loss(574): 0.000074  [    0/   91]\n",
      "loss(575): 0.000068  [    0/   91]\n",
      "loss(576): 0.000076  [    0/   91]\n",
      "loss(577): 0.000095  [    0/   91]\n",
      "loss(578): 0.000082  [    0/   91]\n",
      "loss(579): 0.000081  [    0/   91]\n",
      "loss(580): 0.000095  [    0/   91]\n",
      "loss(581): 0.000065  [    0/   91]\n",
      "loss(582): 0.000078  [    0/   91]\n",
      "loss(583): 0.000101  [    0/   91]\n",
      "loss(584): 0.000082  [    0/   91]\n",
      "loss(585): 0.000085  [    0/   91]\n",
      "loss(586): 0.000064  [    0/   91]\n",
      "loss(587): 0.000061  [    0/   91]\n",
      "loss(588): 0.000084  [    0/   91]\n",
      "loss(589): 0.000082  [    0/   91]\n",
      "loss(590): 0.000093  [    0/   91]\n",
      "loss(591): 0.000098  [    0/   91]\n",
      "loss(592): 0.000055  [    0/   91]\n",
      "loss(593): 0.000109  [    0/   91]\n",
      "loss(594): 0.000106  [    0/   91]\n",
      "loss(595): 0.000100  [    0/   91]\n",
      "loss(596): 0.000086  [    0/   91]\n",
      "loss(597): 0.000096  [    0/   91]\n",
      "loss(598): 0.000080  [    0/   91]\n",
      "loss(599): 0.000099  [    0/   91]\n",
      "loss(600): 0.000119  [    0/   91]\n",
      "loss(601): 0.000087  [    0/   91]\n",
      "loss(602): 0.000083  [    0/   91]\n",
      "loss(603): 0.000054  [    0/   91]\n",
      "loss(604): 0.000089  [    0/   91]\n",
      "loss(605): 0.000085  [    0/   91]\n",
      "loss(606): 0.000087  [    0/   91]\n",
      "loss(607): 0.000070  [    0/   91]\n",
      "loss(608): 0.000078  [    0/   91]\n",
      "loss(609): 0.000095  [    0/   91]\n",
      "loss(610): 0.000088  [    0/   91]\n",
      "loss(611): 0.000071  [    0/   91]\n",
      "loss(612): 0.000096  [    0/   91]\n",
      "loss(613): 0.000066  [    0/   91]\n",
      "loss(614): 0.000086  [    0/   91]\n",
      "loss(615): 0.000061  [    0/   91]\n",
      "loss(616): 0.000092  [    0/   91]\n",
      "loss(617): 0.000126  [    0/   91]\n",
      "loss(618): 0.000076  [    0/   91]\n",
      "loss(619): 0.000086  [    0/   91]\n",
      "loss(620): 0.000082  [    0/   91]\n",
      "loss(621): 0.000088  [    0/   91]\n",
      "loss(622): 0.000099  [    0/   91]\n",
      "loss(623): 0.000104  [    0/   91]\n",
      "loss(624): 0.000107  [    0/   91]\n",
      "loss(625): 0.000067  [    0/   91]\n",
      "loss(626): 0.000087  [    0/   91]\n",
      "loss(627): 0.000102  [    0/   91]\n",
      "loss(628): 0.000109  [    0/   91]\n",
      "loss(629): 0.000074  [    0/   91]\n",
      "loss(630): 0.000092  [    0/   91]\n",
      "loss(631): 0.000092  [    0/   91]\n",
      "loss(632): 0.000097  [    0/   91]\n",
      "loss(633): 0.000064  [    0/   91]\n",
      "loss(634): 0.000084  [    0/   91]\n",
      "loss(635): 0.000090  [    0/   91]\n",
      "loss(636): 0.000094  [    0/   91]\n",
      "loss(637): 0.000095  [    0/   91]\n",
      "loss(638): 0.000089  [    0/   91]\n",
      "loss(639): 0.000091  [    0/   91]\n",
      "loss(640): 0.000071  [    0/   91]\n",
      "loss(641): 0.000061  [    0/   91]\n",
      "loss(642): 0.000079  [    0/   91]\n",
      "loss(643): 0.000090  [    0/   91]\n",
      "loss(644): 0.000095  [    0/   91]\n",
      "loss(645): 0.000070  [    0/   91]\n",
      "loss(646): 0.000078  [    0/   91]\n",
      "loss(647): 0.000093  [    0/   91]\n",
      "loss(648): 0.000064  [    0/   91]\n",
      "loss(649): 0.000103  [    0/   91]\n",
      "loss(650): 0.000094  [    0/   91]\n",
      "loss(651): 0.000063  [    0/   91]\n",
      "loss(652): 0.000086  [    0/   91]\n",
      "loss(653): 0.000063  [    0/   91]\n",
      "loss(654): 0.000054  [    0/   91]\n",
      "loss(655): 0.000089  [    0/   91]\n",
      "loss(656): 0.000081  [    0/   91]\n",
      "loss(657): 0.000063  [    0/   91]\n",
      "loss(658): 0.000087  [    0/   91]\n",
      "loss(659): 0.000085  [    0/   91]\n",
      "loss(660): 0.000082  [    0/   91]\n",
      "loss(661): 0.000089  [    0/   91]\n",
      "loss(662): 0.000079  [    0/   91]\n",
      "loss(663): 0.000083  [    0/   91]\n",
      "loss(664): 0.000080  [    0/   91]\n",
      "loss(665): 0.000071  [    0/   91]\n",
      "loss(666): 0.000084  [    0/   91]\n",
      "loss(667): 0.000102  [    0/   91]\n",
      "loss(668): 0.000086  [    0/   91]\n",
      "loss(669): 0.000068  [    0/   91]\n",
      "loss(670): 0.000083  [    0/   91]\n",
      "loss(671): 0.000063  [    0/   91]\n",
      "loss(672): 0.000083  [    0/   91]\n",
      "loss(673): 0.000081  [    0/   91]\n",
      "loss(674): 0.000089  [    0/   91]\n",
      "loss(675): 0.000086  [    0/   91]\n",
      "loss(676): 0.000090  [    0/   91]\n",
      "loss(677): 0.000081  [    0/   91]\n",
      "loss(678): 0.000083  [    0/   91]\n",
      "loss(679): 0.000084  [    0/   91]\n",
      "loss(680): 0.000089  [    0/   91]\n",
      "loss(681): 0.000062  [    0/   91]\n",
      "loss(682): 0.000093  [    0/   91]\n",
      "loss(683): 0.000087  [    0/   91]\n",
      "loss(684): 0.000075  [    0/   91]\n",
      "loss(685): 0.000083  [    0/   91]\n",
      "loss(686): 0.000098  [    0/   91]\n",
      "loss(687): 0.000092  [    0/   91]\n",
      "loss(688): 0.000089  [    0/   91]\n",
      "loss(689): 0.000086  [    0/   91]\n",
      "loss(690): 0.000081  [    0/   91]\n",
      "loss(691): 0.000101  [    0/   91]\n",
      "loss(692): 0.000090  [    0/   91]\n",
      "loss(693): 0.000085  [    0/   91]\n",
      "loss(694): 0.000098  [    0/   91]\n",
      "loss(695): 0.000093  [    0/   91]\n",
      "loss(696): 0.000091  [    0/   91]\n",
      "loss(697): 0.000078  [    0/   91]\n",
      "loss(698): 0.000080  [    0/   91]\n",
      "loss(699): 0.000056  [    0/   91]\n",
      "loss(700): 0.000081  [    0/   91]\n",
      "loss(701): 0.000063  [    0/   91]\n",
      "loss(702): 0.000088  [    0/   91]\n",
      "loss(703): 0.000057  [    0/   91]\n",
      "loss(704): 0.000102  [    0/   91]\n",
      "loss(705): 0.000112  [    0/   91]\n",
      "loss(706): 0.000088  [    0/   91]\n",
      "loss(707): 0.000090  [    0/   91]\n",
      "loss(708): 0.000134  [    0/   91]\n",
      "loss(709): 0.000095  [    0/   91]\n",
      "loss(710): 0.000099  [    0/   91]\n",
      "loss(711): 0.000083  [    0/   91]\n",
      "loss(712): 0.000090  [    0/   91]\n",
      "loss(713): 0.000066  [    0/   91]\n",
      "loss(714): 0.000069  [    0/   91]\n",
      "loss(715): 0.000085  [    0/   91]\n",
      "loss(716): 0.000063  [    0/   91]\n",
      "loss(717): 0.000068  [    0/   91]\n",
      "loss(718): 0.000084  [    0/   91]\n",
      "loss(719): 0.000081  [    0/   91]\n",
      "loss(720): 0.000087  [    0/   91]\n",
      "loss(721): 0.000085  [    0/   91]\n",
      "loss(722): 0.000098  [    0/   91]\n",
      "loss(723): 0.000063  [    0/   91]\n",
      "loss(724): 0.000077  [    0/   91]\n",
      "loss(725): 0.000066  [    0/   91]\n",
      "loss(726): 0.000080  [    0/   91]\n",
      "loss(727): 0.000080  [    0/   91]\n",
      "loss(728): 0.000076  [    0/   91]\n",
      "loss(729): 0.000082  [    0/   91]\n",
      "loss(730): 0.000084  [    0/   91]\n",
      "loss(731): 0.000091  [    0/   91]\n",
      "loss(732): 0.000088  [    0/   91]\n",
      "loss(733): 0.000095  [    0/   91]\n",
      "loss(734): 0.000118  [    0/   91]\n",
      "loss(735): 0.000105  [    0/   91]\n",
      "loss(736): 0.000082  [    0/   91]\n",
      "loss(737): 0.000066  [    0/   91]\n",
      "loss(738): 0.000097  [    0/   91]\n",
      "loss(739): 0.000082  [    0/   91]\n",
      "loss(740): 0.000083  [    0/   91]\n",
      "loss(741): 0.000089  [    0/   91]\n",
      "loss(742): 0.000095  [    0/   91]\n",
      "loss(743): 0.000060  [    0/   91]\n",
      "loss(744): 0.000086  [    0/   91]\n",
      "loss(745): 0.000077  [    0/   91]\n",
      "loss(746): 0.000082  [    0/   91]\n",
      "loss(747): 0.000069  [    0/   91]\n",
      "loss(748): 0.000083  [    0/   91]\n",
      "loss(749): 0.000077  [    0/   91]\n",
      "loss(750): 0.000066  [    0/   91]\n",
      "loss(751): 0.000088  [    0/   91]\n",
      "loss(752): 0.000075  [    0/   91]\n",
      "loss(753): 0.000078  [    0/   91]\n",
      "loss(754): 0.000087  [    0/   91]\n",
      "loss(755): 0.000083  [    0/   91]\n",
      "loss(756): 0.000061  [    0/   91]\n",
      "loss(757): 0.000090  [    0/   91]\n",
      "loss(758): 0.000076  [    0/   91]\n",
      "loss(759): 0.000061  [    0/   91]\n",
      "loss(760): 0.000061  [    0/   91]\n",
      "loss(761): 0.000081  [    0/   91]\n",
      "loss(762): 0.000085  [    0/   91]\n",
      "loss(763): 0.000113  [    0/   91]\n",
      "loss(764): 0.000089  [    0/   91]\n",
      "loss(765): 0.000084  [    0/   91]\n",
      "loss(766): 0.000084  [    0/   91]\n",
      "loss(767): 0.000089  [    0/   91]\n",
      "loss(768): 0.000090  [    0/   91]\n",
      "loss(769): 0.000065  [    0/   91]\n",
      "loss(770): 0.000080  [    0/   91]\n",
      "loss(771): 0.000084  [    0/   91]\n",
      "loss(772): 0.000081  [    0/   91]\n",
      "loss(773): 0.000082  [    0/   91]\n",
      "loss(774): 0.000087  [    0/   91]\n",
      "loss(775): 0.000058  [    0/   91]\n",
      "loss(776): 0.000083  [    0/   91]\n",
      "loss(777): 0.000080  [    0/   91]\n",
      "loss(778): 0.000076  [    0/   91]\n",
      "loss(779): 0.000064  [    0/   91]\n",
      "loss(780): 0.000068  [    0/   91]\n",
      "loss(781): 0.000078  [    0/   91]\n",
      "loss(782): 0.000077  [    0/   91]\n",
      "loss(783): 0.000068  [    0/   91]\n",
      "loss(784): 0.000084  [    0/   91]\n",
      "loss(785): 0.000085  [    0/   91]\n",
      "loss(786): 0.000093  [    0/   91]\n",
      "loss(787): 0.000083  [    0/   91]\n",
      "loss(788): 0.000057  [    0/   91]\n",
      "loss(789): 0.000075  [    0/   91]\n",
      "loss(790): 0.000068  [    0/   91]\n",
      "loss(791): 0.000084  [    0/   91]\n",
      "loss(792): 0.000087  [    0/   91]\n",
      "loss(793): 0.000056  [    0/   91]\n",
      "loss(794): 0.000080  [    0/   91]\n",
      "loss(795): 0.000071  [    0/   91]\n",
      "loss(796): 0.000105  [    0/   91]\n",
      "loss(797): 0.000083  [    0/   91]\n",
      "loss(798): 0.000071  [    0/   91]\n",
      "loss(799): 0.000062  [    0/   91]\n",
      "loss(800): 0.000100  [    0/   91]\n",
      "loss(801): 0.000074  [    0/   91]\n",
      "loss(802): 0.000104  [    0/   91]\n",
      "loss(803): 0.000090  [    0/   91]\n",
      "loss(804): 0.000080  [    0/   91]\n",
      "loss(805): 0.000081  [    0/   91]\n",
      "loss(806): 0.000083  [    0/   91]\n",
      "loss(807): 0.000081  [    0/   91]\n",
      "loss(808): 0.000075  [    0/   91]\n",
      "loss(809): 0.000080  [    0/   91]\n",
      "loss(810): 0.000087  [    0/   91]\n",
      "loss(811): 0.000082  [    0/   91]\n",
      "loss(812): 0.000080  [    0/   91]\n",
      "loss(813): 0.000084  [    0/   91]\n",
      "loss(814): 0.000076  [    0/   91]\n",
      "loss(815): 0.000078  [    0/   91]\n",
      "loss(816): 0.000055  [    0/   91]\n",
      "loss(817): 0.000098  [    0/   91]\n",
      "loss(818): 0.000104  [    0/   91]\n",
      "loss(819): 0.000077  [    0/   91]\n",
      "loss(820): 0.000063  [    0/   91]\n",
      "loss(821): 0.000078  [    0/   91]\n",
      "loss(822): 0.000092  [    0/   91]\n",
      "loss(823): 0.000106  [    0/   91]\n",
      "loss(824): 0.000076  [    0/   91]\n",
      "loss(825): 0.000079  [    0/   91]\n",
      "loss(826): 0.000081  [    0/   91]\n",
      "loss(827): 0.000092  [    0/   91]\n",
      "loss(828): 0.000073  [    0/   91]\n",
      "loss(829): 0.000071  [    0/   91]\n",
      "loss(830): 0.000076  [    0/   91]\n",
      "loss(831): 0.000086  [    0/   91]\n",
      "loss(832): 0.000081  [    0/   91]\n",
      "loss(833): 0.000081  [    0/   91]\n",
      "loss(834): 0.000076  [    0/   91]\n",
      "loss(835): 0.000089  [    0/   91]\n",
      "loss(836): 0.000081  [    0/   91]\n",
      "loss(837): 0.000065  [    0/   91]\n",
      "loss(838): 0.000076  [    0/   91]\n",
      "loss(839): 0.000090  [    0/   91]\n",
      "loss(840): 0.000086  [    0/   91]\n",
      "loss(841): 0.000085  [    0/   91]\n",
      "loss(842): 0.000079  [    0/   91]\n",
      "loss(843): 0.000109  [    0/   91]\n",
      "loss(844): 0.000087  [    0/   91]\n",
      "loss(845): 0.000074  [    0/   91]\n",
      "loss(846): 0.000076  [    0/   91]\n",
      "loss(847): 0.000095  [    0/   91]\n",
      "loss(848): 0.000084  [    0/   91]\n",
      "loss(849): 0.000062  [    0/   91]\n",
      "loss(850): 0.000064  [    0/   91]\n",
      "loss(851): 0.000062  [    0/   91]\n",
      "loss(852): 0.000080  [    0/   91]\n",
      "loss(853): 0.000081  [    0/   91]\n",
      "loss(854): 0.000071  [    0/   91]\n",
      "loss(855): 0.000119  [    0/   91]\n",
      "loss(856): 0.000097  [    0/   91]\n",
      "loss(857): 0.000086  [    0/   91]\n",
      "loss(858): 0.000079  [    0/   91]\n",
      "loss(859): 0.000078  [    0/   91]\n",
      "loss(860): 0.000076  [    0/   91]\n",
      "loss(861): 0.000078  [    0/   91]\n",
      "loss(862): 0.000078  [    0/   91]\n",
      "loss(863): 0.000063  [    0/   91]\n",
      "loss(864): 0.000114  [    0/   91]\n",
      "loss(865): 0.000108  [    0/   91]\n",
      "loss(866): 0.000068  [    0/   91]\n",
      "loss(867): 0.000079  [    0/   91]\n",
      "loss(868): 0.000067  [    0/   91]\n",
      "loss(869): 0.000099  [    0/   91]\n",
      "loss(870): 0.000089  [    0/   91]\n",
      "loss(871): 0.000084  [    0/   91]\n",
      "loss(872): 0.000076  [    0/   91]\n",
      "loss(873): 0.000084  [    0/   91]\n",
      "loss(874): 0.000080  [    0/   91]\n",
      "loss(875): 0.000061  [    0/   91]\n",
      "loss(876): 0.000081  [    0/   91]\n",
      "loss(877): 0.000083  [    0/   91]\n",
      "loss(878): 0.000078  [    0/   91]\n",
      "loss(879): 0.000078  [    0/   91]\n",
      "loss(880): 0.000098  [    0/   91]\n",
      "loss(881): 0.000072  [    0/   91]\n",
      "loss(882): 0.000055  [    0/   91]\n",
      "loss(883): 0.000079  [    0/   91]\n",
      "loss(884): 0.000082  [    0/   91]\n",
      "loss(885): 0.000066  [    0/   91]\n",
      "loss(886): 0.000076  [    0/   91]\n",
      "loss(887): 0.000079  [    0/   91]\n",
      "loss(888): 0.000056  [    0/   91]\n",
      "loss(889): 0.000059  [    0/   91]\n",
      "loss(890): 0.000083  [    0/   91]\n",
      "loss(891): 0.000071  [    0/   91]\n",
      "loss(892): 0.000064  [    0/   91]\n",
      "loss(893): 0.000090  [    0/   91]\n",
      "loss(894): 0.000083  [    0/   91]\n",
      "loss(895): 0.000080  [    0/   91]\n",
      "loss(896): 0.000052  [    0/   91]\n",
      "loss(897): 0.000061  [    0/   91]\n",
      "loss(898): 0.000087  [    0/   91]\n",
      "loss(899): 0.000096  [    0/   91]\n",
      "loss(900): 0.000093  [    0/   91]\n",
      "loss(901): 0.000074  [    0/   91]\n",
      "loss(902): 0.000065  [    0/   91]\n",
      "loss(903): 0.000088  [    0/   91]\n",
      "loss(904): 0.000066  [    0/   91]\n",
      "loss(905): 0.000100  [    0/   91]\n",
      "loss(906): 0.000102  [    0/   91]\n",
      "loss(907): 0.000084  [    0/   91]\n",
      "loss(908): 0.000085  [    0/   91]\n",
      "loss(909): 0.000084  [    0/   91]\n",
      "loss(910): 0.000067  [    0/   91]\n",
      "loss(911): 0.000095  [    0/   91]\n",
      "loss(912): 0.000109  [    0/   91]\n",
      "loss(913): 0.000080  [    0/   91]\n",
      "loss(914): 0.000093  [    0/   91]\n",
      "loss(915): 0.000074  [    0/   91]\n",
      "loss(916): 0.000062  [    0/   91]\n",
      "loss(917): 0.000086  [    0/   91]\n",
      "loss(918): 0.000081  [    0/   91]\n",
      "loss(919): 0.000061  [    0/   91]\n",
      "loss(920): 0.000081  [    0/   91]\n",
      "loss(921): 0.000072  [    0/   91]\n",
      "loss(922): 0.000070  [    0/   91]\n",
      "loss(923): 0.000056  [    0/   91]\n",
      "loss(924): 0.000066  [    0/   91]\n",
      "loss(925): 0.000082  [    0/   91]\n",
      "loss(926): 0.000067  [    0/   91]\n",
      "loss(927): 0.000085  [    0/   91]\n",
      "loss(928): 0.000082  [    0/   91]\n",
      "loss(929): 0.000080  [    0/   91]\n",
      "loss(930): 0.000083  [    0/   91]\n",
      "loss(931): 0.000081  [    0/   91]\n",
      "loss(932): 0.000075  [    0/   91]\n",
      "loss(933): 0.000075  [    0/   91]\n",
      "loss(934): 0.000080  [    0/   91]\n",
      "loss(935): 0.000087  [    0/   91]\n",
      "loss(936): 0.000085  [    0/   91]\n",
      "loss(937): 0.000061  [    0/   91]\n",
      "loss(938): 0.000073  [    0/   91]\n",
      "loss(939): 0.000078  [    0/   91]\n",
      "loss(940): 0.000063  [    0/   91]\n",
      "loss(941): 0.000105  [    0/   91]\n",
      "loss(942): 0.000097  [    0/   91]\n",
      "loss(943): 0.000067  [    0/   91]\n",
      "loss(944): 0.000084  [    0/   91]\n",
      "loss(945): 0.000096  [    0/   91]\n",
      "loss(946): 0.000097  [    0/   91]\n",
      "loss(947): 0.000081  [    0/   91]\n",
      "loss(948): 0.000085  [    0/   91]\n",
      "loss(949): 0.000078  [    0/   91]\n",
      "loss(950): 0.000069  [    0/   91]\n",
      "loss(951): 0.000102  [    0/   91]\n",
      "loss(952): 0.000081  [    0/   91]\n",
      "loss(953): 0.000084  [    0/   91]\n",
      "loss(954): 0.000083  [    0/   91]\n",
      "loss(955): 0.000095  [    0/   91]\n",
      "loss(956): 0.000087  [    0/   91]\n",
      "loss(957): 0.000076  [    0/   91]\n",
      "loss(958): 0.000080  [    0/   91]\n",
      "loss(959): 0.000066  [    0/   91]\n",
      "loss(960): 0.000058  [    0/   91]\n",
      "loss(961): 0.000079  [    0/   91]\n",
      "loss(962): 0.000084  [    0/   91]\n",
      "loss(963): 0.000089  [    0/   91]\n",
      "loss(964): 0.000081  [    0/   91]\n",
      "loss(965): 0.000077  [    0/   91]\n",
      "loss(966): 0.000073  [    0/   91]\n",
      "loss(967): 0.000074  [    0/   91]\n",
      "loss(968): 0.000078  [    0/   91]\n",
      "loss(969): 0.000075  [    0/   91]\n",
      "loss(970): 0.000067  [    0/   91]\n",
      "loss(971): 0.000060  [    0/   91]\n",
      "loss(972): 0.000054  [    0/   91]\n",
      "loss(973): 0.000065  [    0/   91]\n",
      "loss(974): 0.000072  [    0/   91]\n",
      "loss(975): 0.000076  [    0/   91]\n",
      "loss(976): 0.000057  [    0/   91]\n",
      "loss(977): 0.000079  [    0/   91]\n",
      "loss(978): 0.000077  [    0/   91]\n",
      "loss(979): 0.000055  [    0/   91]\n",
      "loss(980): 0.000084  [    0/   91]\n",
      "loss(981): 0.000100  [    0/   91]\n",
      "loss(982): 0.000080  [    0/   91]\n",
      "loss(983): 0.000057  [    0/   91]\n",
      "loss(984): 0.000067  [    0/   91]\n",
      "loss(985): 0.000055  [    0/   91]\n",
      "loss(986): 0.000070  [    0/   91]\n",
      "loss(987): 0.000087  [    0/   91]\n",
      "loss(988): 0.000106  [    0/   91]\n",
      "loss(989): 0.000097  [    0/   91]\n",
      "loss(990): 0.000075  [    0/   91]\n",
      "loss(991): 0.000075  [    0/   91]\n",
      "loss(992): 0.000080  [    0/   91]\n",
      "loss(993): 0.000076  [    0/   91]\n",
      "loss(994): 0.000098  [    0/   91]\n",
      "loss(995): 0.000076  [    0/   91]\n",
      "loss(996): 0.000059  [    0/   91]\n",
      "loss(997): 0.000051  [    0/   91]\n",
      "loss(998): 0.000081  [    0/   91]\n",
      "loss(999): 0.000074  [    0/   91]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .001\n",
    "epochs = 1000\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# print(list(model.parameters()))\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # break\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "Avg loss: 0.000070 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # print(X)\n",
    "            pred = model(X)\n",
    "            # print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error:\\nAvg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def test(model):\n",
    "    norm = test_data.getNorm()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            Y = test_data[idx][1]*norm\n",
    "            feat = X[None,:]\n",
    "            pred = model(feat)[0]*norm\n",
    "            pred = pred[:,0] \n",
    "            Y = Y[:,0]  \n",
    "            plt.plot(Y)\n",
    "            plt.plot(pred)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def graph(model):\n",
    "    norm = test_data.getNorm()\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            y = test_data[idx][1]*norm\n",
    "            feat = X[None,:]\n",
    "\n",
    "            pred = model(feat)[0]*norm\n",
    "            future = 3\n",
    "\n",
    "            # predY.append(pred[numFeat-1::][future])\n",
    "            # actY.append(y[numFeat-1::][future]) \n",
    "            pred = pred[:,0] \n",
    "            y = y[:,0]  \n",
    "            # print(pred.size())\n",
    "            # print(float(pred[3]))\n",
    "            predY.append(pred[future])\n",
    "            actY.append(y[future])    \n",
    "            \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "graph(model)\n",
    "# test(model)\n",
    "test_loop(test_dataloader,model,loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
