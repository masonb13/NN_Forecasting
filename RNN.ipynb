{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 1\n",
    "train_data = dataSetAll(1900,2013,numFeat,numOut)\n",
    "test_data = dataSetAll(2013,2100,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64,drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64,drop_last=True)\n",
    "# print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 1\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 64\n",
    "batchSize = 64\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numLayers, numOut, sequenceLength=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.numOut = numOut\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.RNN = nn.RNN(inputSize,hiddenSize,numLayers,nonlinearity='relu',batch_first=True)\n",
    "        self.fc = nn.Linear(hiddenSize*sequenceLength,numOut)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.numLayers,x.size(0),self.hiddenSize)\n",
    "        out, _ = self.RNN(x,h0)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "\n",
    "model = RNN(inputSize,hiddenSize,numLayers,numOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch % size == 0:\n",
    "            # loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss.item():>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 9748687.000000\n",
      "loss(1): 8646762.000000\n",
      "loss(2): 7618943.000000\n",
      "loss(3): 5351542.000000\n",
      "loss(4): 2414522.500000\n",
      "loss(5): 2443549.750000\n",
      "loss(6): 2188564.000000\n",
      "loss(7): 1764845.125000\n",
      "loss(8): 1996156.375000\n",
      "loss(9): 1456080.375000\n",
      "loss(10): 1359260.375000\n",
      "loss(11): 1192705.000000\n",
      "loss(12): 1075783.625000\n",
      "loss(13): 1020100.687500\n",
      "loss(14): 1032709.750000\n",
      "loss(15): 849874.000000\n",
      "loss(16): 799054.750000\n",
      "loss(17): 819445.437500\n",
      "loss(18): 1148941.750000\n",
      "loss(19): 681502.062500\n",
      "loss(20): 613307.687500\n",
      "loss(21): 572894.187500\n",
      "loss(22): 543502.687500\n",
      "loss(23): 518605.968750\n",
      "loss(24): 496301.250000\n",
      "loss(25): 475907.812500\n",
      "loss(26): 462669.312500\n",
      "loss(27): 446758.906250\n",
      "loss(28): 437097.781250\n",
      "loss(29): 423376.093750\n",
      "loss(30): 465397.437500\n",
      "loss(31): 416781.531250\n",
      "loss(32): 493761.968750\n",
      "loss(33): 728205.000000\n",
      "loss(34): 447814.781250\n",
      "loss(35): 388812.750000\n",
      "loss(36): 378776.312500\n",
      "loss(37): 358550.156250\n",
      "loss(38): 353336.468750\n",
      "loss(39): 343697.156250\n",
      "loss(40): 343023.531250\n",
      "loss(41): 337080.250000\n",
      "loss(42): 339540.343750\n",
      "loss(43): 329506.593750\n",
      "loss(44): 328789.875000\n",
      "loss(45): 309841.718750\n",
      "loss(46): 312226.843750\n",
      "loss(47): 327699.125000\n",
      "loss(48): 351556.625000\n",
      "loss(49): 324658.125000\n",
      "loss(50): 308099.875000\n",
      "loss(51): 290913.750000\n",
      "loss(52): 283320.000000\n",
      "loss(53): 278417.125000\n",
      "loss(54): 274131.750000\n",
      "loss(55): 270554.343750\n",
      "loss(56): 269412.187500\n",
      "loss(57): 268803.875000\n",
      "loss(58): 273227.156250\n",
      "loss(59): 275831.375000\n",
      "loss(60): 297250.312500\n",
      "loss(61): 321465.156250\n",
      "loss(62): 317771.187500\n",
      "loss(63): 273882.375000\n",
      "loss(64): 250836.500000\n",
      "loss(65): 241841.812500\n",
      "loss(66): 237833.609375\n",
      "loss(67): 235887.109375\n",
      "loss(68): 238103.515625\n",
      "loss(69): 237384.000000\n",
      "loss(70): 244082.250000\n",
      "loss(71): 243166.093750\n",
      "loss(72): 249751.296875\n",
      "loss(73): 282925.062500\n",
      "loss(74): 375404.687500\n",
      "loss(75): 304076.781250\n",
      "loss(76): 243999.406250\n",
      "loss(77): 224864.937500\n",
      "loss(78): 217376.187500\n",
      "loss(79): 218086.015625\n",
      "loss(80): 220051.156250\n",
      "loss(81): 231522.953125\n",
      "loss(82): 242408.531250\n",
      "loss(83): 282308.437500\n",
      "loss(84): 294869.250000\n",
      "loss(85): 259527.656250\n",
      "loss(86): 223182.281250\n",
      "loss(87): 209377.828125\n",
      "loss(88): 206823.437500\n",
      "loss(89): 205704.812500\n",
      "loss(90): 209502.656250\n",
      "loss(91): 209938.406250\n",
      "loss(92): 217094.453125\n",
      "loss(93): 222624.562500\n",
      "loss(94): 242126.265625\n",
      "loss(95): 273399.031250\n",
      "loss(96): 267920.406250\n",
      "loss(97): 222736.453125\n",
      "loss(98): 202544.437500\n",
      "loss(99): 198670.500000\n",
      "loss(100): 197644.312500\n",
      "loss(101): 200262.312500\n",
      "loss(102): 201321.250000\n",
      "loss(103): 208998.968750\n",
      "loss(104): 209658.156250\n",
      "loss(105): 212878.359375\n",
      "loss(106): 244753.828125\n",
      "loss(107): 280734.812500\n",
      "loss(108): 208450.781250\n",
      "loss(109): 209937.906250\n",
      "loss(110): 234456.546875\n",
      "loss(111): 197252.437500\n",
      "loss(112): 203420.046875\n",
      "loss(113): 210586.390625\n",
      "loss(114): 221567.906250\n",
      "loss(115): 213760.953125\n",
      "loss(116): 199584.937500\n",
      "loss(117): 193272.031250\n",
      "loss(118): 194512.109375\n",
      "loss(119): 196355.656250\n",
      "loss(120): 205923.546875\n",
      "loss(121): 195524.000000\n",
      "loss(122): 198937.015625\n",
      "loss(123): 214327.234375\n",
      "loss(124): 208607.750000\n",
      "loss(125): 191331.250000\n",
      "loss(126): 190866.562500\n",
      "loss(127): 191011.750000\n",
      "loss(128): 194589.625000\n",
      "loss(129): 192110.093750\n",
      "loss(130): 190494.156250\n",
      "loss(131): 191850.500000\n",
      "loss(132): 195758.593750\n",
      "loss(133): 192171.906250\n",
      "loss(134): 193011.281250\n",
      "loss(135): 194074.812500\n",
      "loss(136): 196844.140625\n",
      "loss(137): 193339.093750\n",
      "loss(138): 195248.656250\n",
      "loss(139): 189020.062500\n",
      "loss(140): 192831.906250\n",
      "loss(141): 193202.921875\n",
      "loss(142): 192774.250000\n",
      "loss(143): 187521.656250\n",
      "loss(144): 191230.890625\n",
      "loss(145): 190064.203125\n",
      "loss(146): 189024.750000\n",
      "loss(147): 189721.484375\n",
      "loss(148): 193222.343750\n",
      "loss(149): 189644.250000\n",
      "loss(150): 190874.812500\n",
      "loss(151): 188765.468750\n",
      "loss(152): 191874.187500\n",
      "loss(153): 189520.359375\n",
      "loss(154): 190919.406250\n",
      "loss(155): 187589.421875\n",
      "loss(156): 187734.171875\n",
      "loss(157): 187676.500000\n",
      "loss(158): 190578.406250\n",
      "loss(159): 187764.296875\n",
      "loss(160): 188425.937500\n",
      "loss(161): 189681.250000\n",
      "loss(162): 191016.390625\n",
      "loss(163): 189452.406250\n",
      "loss(164): 190677.218750\n",
      "loss(165): 190848.640625\n",
      "loss(166): 195729.640625\n",
      "loss(167): 190657.750000\n",
      "loss(168): 190266.750000\n",
      "loss(169): 189920.593750\n",
      "loss(170): 190342.296875\n",
      "loss(171): 188484.687500\n",
      "loss(172): 193258.015625\n",
      "loss(173): 190920.671875\n",
      "loss(174): 190485.031250\n",
      "loss(175): 189907.843750\n",
      "loss(176): 193780.156250\n",
      "loss(177): 190975.281250\n",
      "loss(178): 194189.031250\n",
      "loss(179): 190542.968750\n",
      "loss(180): 189750.750000\n",
      "loss(181): 190763.531250\n",
      "loss(182): 193004.828125\n",
      "loss(183): 190572.375000\n",
      "loss(184): 193003.859375\n",
      "loss(185): 190562.593750\n",
      "loss(186): 190844.515625\n",
      "loss(187): 191375.375000\n",
      "loss(188): 193817.468750\n",
      "loss(189): 190917.515625\n",
      "loss(190): 192409.437500\n",
      "loss(191): 192305.437500\n",
      "loss(192): 194484.859375\n",
      "loss(193): 192728.781250\n",
      "loss(194): 194298.812500\n",
      "loss(195): 191368.687500\n",
      "loss(196): 196835.093750\n",
      "loss(197): 191241.078125\n",
      "loss(198): 193031.468750\n",
      "loss(199): 189399.296875\n",
      "loss(200): 188954.546875\n",
      "loss(201): 192100.531250\n",
      "loss(202): 193044.687500\n",
      "loss(203): 191694.750000\n",
      "loss(204): 193501.093750\n",
      "loss(205): 189855.171875\n",
      "loss(206): 192337.812500\n",
      "loss(207): 192594.562500\n",
      "loss(208): 192002.906250\n",
      "loss(209): 194772.625000\n",
      "loss(210): 195321.187500\n",
      "loss(211): 189475.406250\n",
      "loss(212): 187225.687500\n",
      "loss(213): 189734.312500\n",
      "loss(214): 188210.796875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\RNN.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\RNN.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(\"pred\",pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# print(\"Y\",y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# loss, current = loss.item(), batch * len(X)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = .001\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  ary = asanyarray(ary)\n",
      "c:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "def graph(model):\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            predY.append(pred)\n",
    "            actY.append(y)\n",
    "            # plt.plot(np.append(feat,pred))\n",
    "            # plt.plot(np.append(feat,y))\n",
    "            \n",
    "            \n",
    "        \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "# test_loop(test_dataloader,model)\n",
    "graph(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
