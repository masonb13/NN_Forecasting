{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CDC\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "        #turn data into features and output\n",
    "        #features: 5 previous + one from last year for predicted\n",
    "        #output: prediction for next time\n",
    "\n",
    "        #create test data\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        self.data = self.data / np.linalg.norm(self.data)\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]\n",
    "        # return self.data[idx:idx+self.numFeat],self.data[idx:idx+self.numFeat+self.numOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 1\n",
    "train_data = dataSetAll(1900,2013,numFeat,numOut)\n",
    "test_data = dataSetAll(2013,2100,numFeat,numOut)\n",
    "train_dataloader = DataLoader(train_data, batch_size=100,drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100,drop_last=True)\n",
    "# print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 1\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 64\n",
    "batchSize = 100\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numLayers, numOut, sequenceLength=1,future=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.numOut = numOut\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.future = future\n",
    "        # self.RNN = nn.RNN(inputSize,hiddenSize,numLayers,nonlinearity='relu',batch_first=True)\n",
    "        self.RNN1 = nn.RNNCell(inputSize,hiddenSize,nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hiddenSize,numOut)\n",
    "        \n",
    "    # def forward(self,x):\n",
    "    #     h0 = torch.zeros(self.numLayers,x.size(0),self.hiddenSize)\n",
    "    #     out, _ = self.RNN(x,h0)\n",
    "    #     out = self.fc(out[:,-1,:])\n",
    "    #     return out\n",
    "\n",
    "    def forward(self,x):\n",
    "        outputs = []\n",
    "        nSamples = x.size(0)\n",
    "        # print(nSamples,self.hiddenSize)\n",
    "        h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        \n",
    "        for input in x.split(1,dim=1):\n",
    "            h_1 = self.RNN1(input, h_1)\n",
    "            out = self.fc(h_1)\n",
    "            # outputs.append(out)\n",
    "\n",
    "        # for i in range(self.future):\n",
    "        #     h_1 = self.RNN1(input, h_1)\n",
    "        #     out = self.fc(h_1)\n",
    "        #     outputs.append(out)\n",
    "        \n",
    "        # outputs = torch.cat(outputs, dim=1)\n",
    "        # return outputs[-1]\n",
    "        return out\n",
    "\n",
    "model = RNN(inputSize,hiddenSize,numLayers,numOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # X = X[:,:,None]\n",
    "        # print(X.size())\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(\"pred\",pred)\n",
    "        # print(\"Y\",y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch % size == 0:\n",
    "            # loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss.item():>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(0): 0.004770\n",
      "loss(1): 0.003597\n",
      "loss(2): 0.002618\n",
      "loss(3): 0.001837\n",
      "loss(4): 0.001239\n",
      "loss(5): 0.000799\n",
      "loss(6): 0.000491\n",
      "loss(7): 0.000293\n",
      "loss(8): 0.000180\n",
      "loss(9): 0.000132\n",
      "loss(10): 0.000129\n",
      "loss(11): 0.000152\n",
      "loss(12): 0.000188\n",
      "loss(13): 0.000223\n",
      "loss(14): 0.000248\n",
      "loss(15): 0.000262\n",
      "loss(16): 0.000267\n",
      "loss(17): 0.000266\n",
      "loss(18): 0.000263\n",
      "loss(19): 0.000260\n",
      "loss(20): 0.000257\n",
      "loss(21): 0.000254\n",
      "loss(22): 0.000253\n",
      "loss(23): 0.000252\n",
      "loss(24): 0.000252\n",
      "loss(25): 0.000252\n",
      "loss(26): 0.000252\n",
      "loss(27): 0.000252\n",
      "loss(28): 0.000252\n",
      "loss(29): 0.000252\n",
      "loss(30): 0.000251\n",
      "loss(31): 0.000251\n",
      "loss(32): 0.000250\n",
      "loss(33): 0.000250\n",
      "loss(34): 0.000249\n",
      "loss(35): 0.000248\n",
      "loss(36): 0.000248\n",
      "loss(37): 0.000247\n",
      "loss(38): 0.000247\n",
      "loss(39): 0.000246\n",
      "loss(40): 0.000245\n",
      "loss(41): 0.000245\n",
      "loss(42): 0.000244\n",
      "loss(43): 0.000244\n",
      "loss(44): 0.000243\n",
      "loss(45): 0.000243\n",
      "loss(46): 0.000242\n",
      "loss(47): 0.000242\n",
      "loss(48): 0.000241\n",
      "loss(49): 0.000240\n",
      "loss(50): 0.000240\n",
      "loss(51): 0.000239\n",
      "loss(52): 0.000239\n",
      "loss(53): 0.000238\n",
      "loss(54): 0.000237\n",
      "loss(55): 0.000237\n",
      "loss(56): 0.000236\n",
      "loss(57): 0.000235\n",
      "loss(58): 0.000235\n",
      "loss(59): 0.000234\n",
      "loss(60): 0.000233\n",
      "loss(61): 0.000233\n",
      "loss(62): 0.000232\n",
      "loss(63): 0.000231\n",
      "loss(64): 0.000231\n",
      "loss(65): 0.000230\n",
      "loss(66): 0.000229\n",
      "loss(67): 0.000229\n",
      "loss(68): 0.000228\n",
      "loss(69): 0.000227\n",
      "loss(70): 0.000226\n",
      "loss(71): 0.000226\n",
      "loss(72): 0.000225\n",
      "loss(73): 0.000224\n",
      "loss(74): 0.000224\n",
      "loss(75): 0.000223\n",
      "loss(76): 0.000222\n",
      "loss(77): 0.000221\n",
      "loss(78): 0.000221\n",
      "loss(79): 0.000220\n",
      "loss(80): 0.000219\n",
      "loss(81): 0.000218\n",
      "loss(82): 0.000218\n",
      "loss(83): 0.000217\n",
      "loss(84): 0.000216\n",
      "loss(85): 0.000215\n",
      "loss(86): 0.000215\n",
      "loss(87): 0.000214\n",
      "loss(88): 0.000213\n",
      "loss(89): 0.000212\n",
      "loss(90): 0.000211\n",
      "loss(91): 0.000210\n",
      "loss(92): 0.000210\n",
      "loss(93): 0.000209\n",
      "loss(94): 0.000208\n",
      "loss(95): 0.000207\n",
      "loss(96): 0.000206\n",
      "loss(97): 0.000205\n",
      "loss(98): 0.000204\n",
      "loss(99): 0.000204\n",
      "loss(100): 0.000203\n",
      "loss(101): 0.000202\n",
      "loss(102): 0.000201\n",
      "loss(103): 0.000200\n",
      "loss(104): 0.000199\n",
      "loss(105): 0.000198\n",
      "loss(106): 0.000197\n",
      "loss(107): 0.000196\n",
      "loss(108): 0.000195\n",
      "loss(109): 0.000194\n",
      "loss(110): 0.000193\n",
      "loss(111): 0.000192\n",
      "loss(112): 0.000191\n",
      "loss(113): 0.000190\n",
      "loss(114): 0.000189\n",
      "loss(115): 0.000188\n",
      "loss(116): 0.000187\n",
      "loss(117): 0.000186\n",
      "loss(118): 0.000185\n",
      "loss(119): 0.000184\n",
      "loss(120): 0.000183\n",
      "loss(121): 0.000182\n",
      "loss(122): 0.000181\n",
      "loss(123): 0.000180\n",
      "loss(124): 0.000179\n",
      "loss(125): 0.000178\n",
      "loss(126): 0.000177\n",
      "loss(127): 0.000176\n",
      "loss(128): 0.000175\n",
      "loss(129): 0.000175\n",
      "loss(130): 0.000174\n",
      "loss(131): 0.000172\n",
      "loss(132): 0.000170\n",
      "loss(133): 0.000169\n",
      "loss(134): 0.000169\n",
      "loss(135): 0.000168\n",
      "loss(136): 0.000166\n",
      "loss(137): 0.000165\n",
      "loss(138): 0.000163\n",
      "loss(139): 0.000163\n",
      "loss(140): 0.000162\n",
      "loss(141): 0.000160\n",
      "loss(142): 0.000158\n",
      "loss(143): 0.000157\n",
      "loss(144): 0.000157\n",
      "loss(145): 0.000156\n",
      "loss(146): 0.000154\n",
      "loss(147): 0.000152\n",
      "loss(148): 0.000151\n",
      "loss(149): 0.000150\n",
      "loss(150): 0.000150\n",
      "loss(151): 0.000148\n",
      "loss(152): 0.000146\n",
      "loss(153): 0.000144\n",
      "loss(154): 0.000144\n",
      "loss(155): 0.000143\n",
      "loss(156): 0.000141\n",
      "loss(157): 0.000139\n",
      "loss(158): 0.000139\n",
      "loss(159): 0.000137\n",
      "loss(160): 0.000135\n",
      "loss(161): 0.000134\n",
      "loss(162): 0.000133\n",
      "loss(163): 0.000131\n",
      "loss(164): 0.000130\n",
      "loss(165): 0.000129\n",
      "loss(166): 0.000127\n",
      "loss(167): 0.000126\n",
      "loss(168): 0.000124\n",
      "loss(169): 0.000123\n",
      "loss(170): 0.000122\n",
      "loss(171): 0.000120\n",
      "loss(172): 0.000118\n",
      "loss(173): 0.000118\n",
      "loss(174): 0.000116\n",
      "loss(175): 0.000114\n",
      "loss(176): 0.000114\n",
      "loss(177): 0.000112\n",
      "loss(178): 0.000110\n",
      "loss(179): 0.000108\n",
      "loss(180): 0.000107\n",
      "loss(181): 0.000105\n",
      "loss(182): 0.000103\n",
      "loss(183): 0.000103\n",
      "loss(184): 0.000101\n",
      "loss(185): 0.000099\n",
      "loss(186): 0.000098\n",
      "loss(187): 0.000096\n",
      "loss(188): 0.000095\n",
      "loss(189): 0.000093\n",
      "loss(190): 0.000092\n",
      "loss(191): 0.000090\n",
      "loss(192): 0.000089\n",
      "loss(193): 0.000088\n",
      "loss(194): 0.000086\n",
      "loss(195): 0.000084\n",
      "loss(196): 0.000084\n",
      "loss(197): 0.000083\n",
      "loss(198): 0.000080\n",
      "loss(199): 0.000072\n",
      "loss(200): 0.000070\n",
      "loss(201): 0.000070\n",
      "loss(202): 0.000066\n",
      "loss(203): 0.000064\n",
      "loss(204): 0.000063\n",
      "loss(205): 0.000061\n",
      "loss(206): 0.000060\n",
      "loss(207): 0.000058\n",
      "loss(208): 0.000057\n",
      "loss(209): 0.000056\n",
      "loss(210): 0.000055\n",
      "loss(211): 0.000053\n",
      "loss(212): 0.000061\n",
      "loss(213): 0.000051\n",
      "loss(214): 0.000050\n",
      "loss(215): 0.000053\n",
      "loss(216): 0.000047\n",
      "loss(217): 0.000046\n",
      "loss(218): 0.000045\n",
      "loss(219): 0.000045\n",
      "loss(220): 0.000043\n",
      "loss(221): 0.000042\n",
      "loss(222): 0.000042\n",
      "loss(223): 0.000041\n",
      "loss(224): 0.000040\n",
      "loss(225): 0.000039\n",
      "loss(226): 0.000038\n",
      "loss(227): 0.000038\n",
      "loss(228): 0.000037\n",
      "loss(229): 0.000036\n",
      "loss(230): 0.000036\n",
      "loss(231): 0.000035\n",
      "loss(232): 0.000035\n",
      "loss(233): 0.000035\n",
      "loss(234): 0.000034\n",
      "loss(235): 0.000034\n",
      "loss(236): 0.000034\n",
      "loss(237): 0.000033\n",
      "loss(238): 0.000033\n",
      "loss(239): 0.000033\n",
      "loss(240): 0.000033\n",
      "loss(241): 0.000032\n",
      "loss(242): 0.000033\n",
      "loss(243): 0.000032\n",
      "loss(244): 0.000032\n",
      "loss(245): 0.000032\n",
      "loss(246): 0.000032\n",
      "loss(247): 0.000032\n",
      "loss(248): 0.000031\n",
      "loss(249): 0.000031\n",
      "loss(250): 0.000031\n",
      "loss(251): 0.000031\n",
      "loss(252): 0.000031\n",
      "loss(253): 0.000031\n",
      "loss(254): 0.000031\n",
      "loss(255): 0.000030\n",
      "loss(256): 0.000031\n",
      "loss(257): 0.000030\n",
      "loss(258): 0.000030\n",
      "loss(259): 0.000030\n",
      "loss(260): 0.000030\n",
      "loss(261): 0.000030\n",
      "loss(262): 0.000030\n",
      "loss(263): 0.000030\n",
      "loss(264): 0.000030\n",
      "loss(265): 0.000029\n",
      "loss(266): 0.000029\n",
      "loss(267): 0.000029\n",
      "loss(268): 0.000029\n",
      "loss(269): 0.000029\n",
      "loss(270): 0.000029\n",
      "loss(271): 0.000029\n",
      "loss(272): 0.000029\n",
      "loss(273): 0.000029\n",
      "loss(274): 0.000029\n",
      "loss(275): 0.000029\n",
      "loss(276): 0.000028\n",
      "loss(277): 0.000028\n",
      "loss(278): 0.000028\n",
      "loss(279): 0.000028\n",
      "loss(280): 0.000028\n",
      "loss(281): 0.000028\n",
      "loss(282): 0.000028\n",
      "loss(283): 0.000028\n",
      "loss(284): 0.000028\n",
      "loss(285): 0.000028\n",
      "loss(286): 0.000028\n",
      "loss(287): 0.000028\n",
      "loss(288): 0.000027\n",
      "loss(289): 0.000027\n",
      "loss(290): 0.000027\n",
      "loss(291): 0.000027\n",
      "loss(292): 0.000027\n",
      "loss(293): 0.000027\n",
      "loss(294): 0.000027\n",
      "loss(295): 0.000027\n",
      "loss(296): 0.000027\n",
      "loss(297): 0.000027\n",
      "loss(298): 0.000027\n",
      "loss(299): 0.000027\n",
      "loss(300): 0.000027\n",
      "loss(301): 0.000027\n",
      "loss(302): 0.000027\n",
      "loss(303): 0.000027\n",
      "loss(304): 0.000026\n",
      "loss(305): 0.000026\n",
      "loss(306): 0.000026\n",
      "loss(307): 0.000026\n",
      "loss(308): 0.000026\n",
      "loss(309): 0.000026\n",
      "loss(310): 0.000026\n",
      "loss(311): 0.000026\n",
      "loss(312): 0.000026\n",
      "loss(313): 0.000026\n",
      "loss(314): 0.000026\n",
      "loss(315): 0.000026\n",
      "loss(316): 0.000026\n",
      "loss(317): 0.000026\n",
      "loss(318): 0.000026\n",
      "loss(319): 0.000026\n",
      "loss(320): 0.000026\n",
      "loss(321): 0.000026\n",
      "loss(322): 0.000026\n",
      "loss(323): 0.000026\n",
      "loss(324): 0.000025\n",
      "loss(325): 0.000025\n",
      "loss(326): 0.000025\n",
      "loss(327): 0.000025\n",
      "loss(328): 0.000025\n",
      "loss(329): 0.000025\n",
      "loss(330): 0.000025\n",
      "loss(331): 0.000025\n",
      "loss(332): 0.000025\n",
      "loss(333): 0.000025\n",
      "loss(334): 0.000025\n",
      "loss(335): 0.000025\n",
      "loss(336): 0.000025\n",
      "loss(337): 0.000025\n",
      "loss(338): 0.000025\n",
      "loss(339): 0.000025\n",
      "loss(340): 0.000025\n",
      "loss(341): 0.000025\n",
      "loss(342): 0.000025\n",
      "loss(343): 0.000025\n",
      "loss(344): 0.000024\n",
      "loss(345): 0.000025\n",
      "loss(346): 0.000024\n",
      "loss(347): 0.000024\n",
      "loss(348): 0.000024\n",
      "loss(349): 0.000024\n",
      "loss(350): 0.000024\n",
      "loss(351): 0.000024\n",
      "loss(352): 0.000024\n",
      "loss(353): 0.000024\n",
      "loss(354): 0.000024\n",
      "loss(355): 0.000024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\RNN.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\RNN.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# X = X[:,:,None]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# print(X.size())\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# print(\"pred\",pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# print(\"Y\",y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\RNN.ipynb Cell 6\u001b[0m in \u001b[0;36mRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m h_1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(nSamples, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhiddenSize, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39msplit(\u001b[39m1\u001b[39m,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     h_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mRNN1(\u001b[39minput\u001b[39;49m, h_1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(h_1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# outputs.append(out)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# for i in range(self.future):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# outputs = torch.cat(outputs, dim=1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/RNN.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# return outputs[-1]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1100\u001b[0m, in \u001b[0;36mRNNCell.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1094\u001b[0m     ret \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mrnn_tanh_cell(\n\u001b[0;32m   1095\u001b[0m         \u001b[39minput\u001b[39m, hx,\n\u001b[0;32m   1096\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_ih, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_hh,\n\u001b[0;32m   1097\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_ih, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_hh,\n\u001b[0;32m   1098\u001b[0m     )\n\u001b[0;32m   1099\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnonlinearity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1100\u001b[0m     ret \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mrnn_relu_cell(\n\u001b[0;32m   1101\u001b[0m         \u001b[39minput\u001b[39;49m, hx,\n\u001b[0;32m   1102\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_hh,\n\u001b[0;32m   1103\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_hh,\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m  \u001b[39m# TODO: remove when jit supports exception flow\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = .0001\n",
    "epochs = 1000\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  ary = asanyarray(ary)\n",
      "c:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    yearLow = 2013\n",
    "    yearHigh = 2020\n",
    "    df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "    df = df[(yearLow <= df[\"YEAR\"]) & (df[\"YEAR\"] < yearHigh)][\"TOTAL\"]\n",
    "    data = np.array(df)\n",
    "    numFeat = 10 #------------------------\n",
    "    numOut = 1\n",
    "\n",
    "    size = len(data)-numFeat-numOut\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(4,len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:,None]\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            plt.plot(np.append(feat,pred))\n",
    "            plt.plot(np.append(feat,y))\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "def graph(model):\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            feat = test_data[idx][0]\n",
    "            y = test_data[idx][1]\n",
    "            X = feat[None,:]\n",
    "            # print(X.size())\n",
    "            pred = model(X).squeeze().numpy()\n",
    "            # print(pred[0])\n",
    "            predY.append(pred)\n",
    "            actY.append(y)\n",
    "            # plt.plot(np.append(feat,pred))\n",
    "            # plt.plot(np.append(feat,y))\n",
    "            \n",
    "        \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "# test_loop(test_dataloader,model)\n",
    "graph(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
