{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch data set\n",
    "class dataSetAll(Dataset):\n",
    "    def __init__(self, yearLow, yearHigh,numFeat,numOut):\n",
    "        #import data from CSV\n",
    "        self.df = pd.read_csv(\"data\\FluViewPhase2Data\\WHO_NREVSS_Combined_prior_to_2015_16.csv\")\n",
    "        self.df = self.df[(yearLow <= self.df[\"YEAR\"]) & (self.df[\"YEAR\"] < yearHigh)][[\"TOTAL\",\"PERCENT POSITIVE\"]]\n",
    "\n",
    "        self.numFeat = numFeat #------------------------\n",
    "        self.numOut = numOut\n",
    "        \n",
    "        self.data = np.asarray(self.df,dtype=np.float32)\n",
    "        # print(self.data)\n",
    "        self.norm = np.linalg.norm(self.data, axis=0)\n",
    "        # print(self.norm)\n",
    "        self.data = self.data / self.norm\n",
    "        self.data = torch.as_tensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-self.numFeat-self.numOut\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # idx = 0\n",
    "        return self.data[idx:idx+self.numFeat],self.data[idx+self.numFeat:idx+self.numFeat+self.numOut]\n",
    "    \n",
    "    def getNorm(self):\n",
    "        return self.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0176, 0.0017],\n",
      "        [0.0200, 0.0021],\n",
      "        [0.0222, 0.0011],\n",
      "        [0.0232, 0.0014],\n",
      "        [0.0267, 0.0036],\n",
      "        [0.0236, 0.0065],\n",
      "        [0.0274, 0.0061],\n",
      "        [0.0325, 0.0126],\n",
      "        [0.0359, 0.0282],\n",
      "        [0.0353, 0.0499]]), tensor([[0.0557, 0.0764],\n",
      "        [0.0579, 0.0828],\n",
      "        [0.0652, 0.1014],\n",
      "        [0.0708, 0.1111]]))\n"
     ]
    }
   ],
   "source": [
    "#create data loaders\n",
    "numFeat = 10\n",
    "numOut = 4\n",
    "batchSize = 64\n",
    "train_data = dataSetAll(1900,2009,numFeat,numOut)\n",
    "print(train_data[0])\n",
    "train_dataloader = DataLoader(train_data, batch_size=batchSize,drop_last=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our RNN based network with an RNN followed by a linear layer\n",
    "inputSize = 2\n",
    "sequenceLength = numFeat\n",
    "numLayers = 1\n",
    "hiddenSize = 16\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,numLayers,numOut,sequenceLength,future=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.inputSize = inputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        self.numOut = numOut\n",
    "        self.future = future\n",
    "        # print(batchSize,sequenceLength,inputSize)\n",
    "        # self.LSTM = nn.LSTM(inputSize,hiddenSize,numLayers,batch_first=True)\n",
    "        self.rnn = nn.RNNCell(inputSize,hiddenSize,nonlinearity='relu')\n",
    "        # self.rnn2 = nn.RNNCell(1,hiddenSize,nonlinearity='tanh')\n",
    "        self.fc = nn.Linear(hiddenSize,inputSize)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        outputs = []\n",
    "        nSamples = x.size(0)\n",
    "        h_1 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "        h_2 = torch.zeros(nSamples, self.hiddenSize, dtype=torch.float32)\n",
    "\n",
    "        for input in x.split(1,dim=1):\n",
    "            print(input[:,0,:].size())\n",
    "            h_1 = self.rnn(input[:,0,:], h_1)\n",
    "            out = self.fc(h_1)\n",
    "        outputs.append(out)\n",
    "            # h_2 = h_1\n",
    "        for i in range(self.numOut-1):\n",
    "            h_1 = self.rnn(out, h_1)\n",
    "            out = self.fc(h_1)\n",
    "            outputs.append(out)\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "model = RNN(inputSize,hiddenSize,numLayers,numOut,sequenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        # print(X.size())\n",
    "        # X = X[:,:,None]\n",
    "        print(X.size())\n",
    "        pred = model(X)\n",
    "        break\n",
    "        # print(pred.size())\n",
    "        # print(y.size())\n",
    "        # print(\"pred\",pred.size())\n",
    "        # print(\"Y\",y.size())\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % size == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss({t}): {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\_RNNMulti.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(list(model.parameters()))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\_RNNMulti.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# print(X.size())\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# X = X[:,:,None]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39msize())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# print(pred.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# print(y.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# print(\"pred\",pred.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# print(\"Y\",y.size())\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mburs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\_RNNMulti.ipynb Cell 6\u001b[0m in \u001b[0;36mRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39minput\u001b[39m[:,\u001b[39m0\u001b[39m,:]\u001b[39m.\u001b[39msize())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     h_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(\u001b[39minput\u001b[39m[:,\u001b[39m0\u001b[39m,:], h_1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     tot, per \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(h_1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m outputs\u001b[39m.\u001b[39mappend(tot)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# h_2 = h_1\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "learning_rate = .001\n",
    "epochs = 200\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# print(list(model.parameters()))\n",
    "\n",
    "# print(list(model.parameters()))\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer,t)\n",
    "    break\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\_RNNMulti.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         plt\u001b[39m.\u001b[39mplot(predY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m graph(model)\n",
      "\u001b[1;32mc:\\Users\\mburs\\OneDrive - Lehigh University\\Opportunities\\Winter2022 Projects\\NN\\_RNNMulti.ipynb Cell 7\u001b[0m in \u001b[0;36mgraph\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test_data)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     X \u001b[39m=\u001b[39m test_data[idx][\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     y \u001b[39m=\u001b[39m test_data[idx][\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49mnorm\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     feat \u001b[39m=\u001b[39m X[\u001b[39mNone\u001b[39;00m,:]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mburs/OneDrive%20-%20Lehigh%20University/Opportunities/Winter2022%20Projects/NN/_RNNMulti.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(feat)[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mnorm\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (2,) "
     ]
    }
   ],
   "source": [
    "def test_loop(model):\n",
    "    test_data = dataSetAll(2010,2100,numFeat,numOut)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            Y = test_data[idx][1]\n",
    "            feat = X[None,:]\n",
    "            pred = model(feat)[0]\n",
    "            plt.plot(Y)\n",
    "            plt.plot(pred)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def graph(model):\n",
    "    test_data = dataSetAll(2010,2100,numFeat,numOut)\n",
    "    norm = test_data.getNorm()\n",
    "    with torch.no_grad():\n",
    "        predY = []\n",
    "        actY = []\n",
    "        for idx in range(len(test_data)):\n",
    "            X = test_data[idx][0]\n",
    "            y = test_data[idx][1]*norm\n",
    "            feat = X[None,:]\n",
    "\n",
    "            pred = model(feat)[0]*norm\n",
    "            future = 3\n",
    "\n",
    "            # predY.append(pred[numFeat-1::][future])\n",
    "            # actY.append(y[numFeat-1::][future])    \n",
    "            predY.append(pred[future])\n",
    "            actY.append(y[future])    \n",
    "            \n",
    "        plt.plot(actY) \n",
    "        plt.plot(predY)\n",
    "        plt.show()\n",
    "\n",
    "graph(model)\n",
    "# test_loop(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a148e496c0f49d57628151d2aab378855c5a8a7aaacdf2673cbe18e166795068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
